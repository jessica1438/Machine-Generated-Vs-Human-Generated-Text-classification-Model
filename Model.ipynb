{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-UHKDSOaegOC"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS,CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from ast import literal_eval\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hyuzepj5uWFQ"
   },
   "source": [
    "## import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "v_BvDZfWfCR-"
   },
   "outputs": [],
   "source": [
    "fifa = 'fifa_df_en_10k_del_url_w_stpw.csv'\n",
    "g_of_t = 'game_df_en_10k_del_url_w_stpw.csv'\n",
    "election = 'election_df_en_10k_del_url_w_stpw_use.csv'\n",
    "\n",
    "\n",
    "fifa_machine = 'fifa_df_machine_60_perc_10k_0404.csv'\n",
    "g_of_t_machine = 'game_paraphrase_df.csv'\n",
    "election_machine = 'election_df_machine_60_perc_10k_0404.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_per_datasets = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 615
    },
    "id": "q-heKwK1hsRl",
    "outputId": "de282cb1-484f-42bf-c05f-f3a84312d5ff"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>Topics</th>\n",
       "      <th>Human_generated</th>\n",
       "      <th>count_url</th>\n",
       "      <th>count_emoji</th>\n",
       "      <th>count_profile</th>\n",
       "      <th>clean_tweet_Length</th>\n",
       "      <th>Tweet_Length</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>tokenize_clean_tweet</th>\n",
       "      <th>token_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gw1 prediction qat 1 2 ecu sen 0 2 netherland...</td>\n",
       "      <td>Fifa</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>279</td>\n",
       "      <td>279</td>\n",
       "      <td>#WorldCup2022 GW1 Predictions\\n \\n#Qat 1-2 #Ec...</td>\n",
       "      <td>['worldcup2022', 'gw1', 'prediction', 'qat', '...</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this world cup be corrupt even more now so it ...</td>\n",
       "      <td>Fifa</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>279</td>\n",
       "      <td>300</td>\n",
       "      <td>This World Cup is corrupt even more now so it‚Äô...</td>\n",
       "      <td>['this', 'world', 'cup', 'be', 'corrupt', 'eve...</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hypocrisy it be sad that all this talk here in...</td>\n",
       "      <td>Fifa</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>271</td>\n",
       "      <td>271</td>\n",
       "      <td>Hypocrisy it is sad that all this talk here in...</td>\n",
       "      <td>['hypocrisy', 'it', 'be', 'sad', 'that', 'all'...</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it only come every 4 year so even though there...</td>\n",
       "      <td>Fifa</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>273</td>\n",
       "      <td>279</td>\n",
       "      <td>It only comes every 4 years so even though the...</td>\n",
       "      <td>['it', 'only', 'come', 'every', '4', 'year', '...</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the part about not sell alcohol at  to match g...</td>\n",
       "      <td>Fifa</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>268</td>\n",
       "      <td>268</td>\n",
       "      <td>The part about not selling alcohol at #WorldCu...</td>\n",
       "      <td>['the', 'part', 'about', 'not', 'sell', 'alcoh...</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19970</th>\n",
       "      <td>cheer</td>\n",
       "      <td>Fifa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>Cheers</td>\n",
       "      <td>['cheer']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19971</th>\n",
       "      <td>goat</td>\n",
       "      <td>Fifa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>GOAT ‚öΩÔ∏è @Cristiano üáµüáπ</td>\n",
       "      <td>['goat']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19972</th>\n",
       "      <td>yesssss</td>\n",
       "      <td>Fifa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>YESSSSS</td>\n",
       "      <td>['yesssss']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19973</th>\n",
       "      <td>germany</td>\n",
       "      <td>Fifa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>@KuWallet Germany</td>\n",
       "      <td>['germany']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19974</th>\n",
       "      <td></td>\n",
       "      <td>Fifa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>#WorldCup2022</td>\n",
       "      <td>['worldcup2022']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19975 rows √ó 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             clean_tweet Topics  \\\n",
       "0       gw1 prediction qat 1 2 ecu sen 0 2 netherland...   Fifa   \n",
       "1      this world cup be corrupt even more now so it ...   Fifa   \n",
       "2      hypocrisy it be sad that all this talk here in...   Fifa   \n",
       "3      it only come every 4 year so even though there...   Fifa   \n",
       "4      the part about not sell alcohol at  to match g...   Fifa   \n",
       "...                                                  ...    ...   \n",
       "19970                                              cheer   Fifa   \n",
       "19971                                               goat   Fifa   \n",
       "19972                                            yesssss   Fifa   \n",
       "19973                                            germany   Fifa   \n",
       "19974                                                      Fifa   \n",
       "\n",
       "       Human_generated  count_url  count_emoji  count_profile  \\\n",
       "0                    1          0            0              0   \n",
       "1                    1          1            0              0   \n",
       "2                    1          0            0              0   \n",
       "3                    1          0            1              0   \n",
       "4                    1          0            0              0   \n",
       "...                ...        ...          ...            ...   \n",
       "19970                0          0            0              0   \n",
       "19971                0          0            2              1   \n",
       "19972                0          0            0              0   \n",
       "19973                0          0            0              1   \n",
       "19974                0          0            0              0   \n",
       "\n",
       "       clean_tweet_Length  Tweet_Length  \\\n",
       "0                     279           279   \n",
       "1                     279           300   \n",
       "2                     271           271   \n",
       "3                     273           279   \n",
       "4                     268           268   \n",
       "...                   ...           ...   \n",
       "19970                   6             6   \n",
       "19971                   4            21   \n",
       "19972                   7             7   \n",
       "19973                   7            17   \n",
       "19974                  13            14   \n",
       "\n",
       "                                                   Tweet  \\\n",
       "0      #WorldCup2022 GW1 Predictions\\n \\n#Qat 1-2 #Ec...   \n",
       "1      This World Cup is corrupt even more now so it‚Äô...   \n",
       "2      Hypocrisy it is sad that all this talk here in...   \n",
       "3      It only comes every 4 years so even though the...   \n",
       "4      The part about not selling alcohol at #WorldCu...   \n",
       "...                                                  ...   \n",
       "19970                                             Cheers   \n",
       "19971                              GOAT ‚öΩÔ∏è @Cristiano üáµüáπ   \n",
       "19972                                            YESSSSS   \n",
       "19973                                  @KuWallet Germany   \n",
       "19974                                     #WorldCup2022    \n",
       "\n",
       "                                    tokenize_clean_tweet  token_length  \n",
       "0      ['worldcup2022', 'gw1', 'prediction', 'qat', '...            67  \n",
       "1      ['this', 'world', 'cup', 'be', 'corrupt', 'eve...            57  \n",
       "2      ['hypocrisy', 'it', 'be', 'sad', 'that', 'all'...            57  \n",
       "3      ['it', 'only', 'come', 'every', '4', 'year', '...            57  \n",
       "4      ['the', 'part', 'about', 'not', 'sell', 'alcoh...            56  \n",
       "...                                                  ...           ...  \n",
       "19970                                          ['cheer']             1  \n",
       "19971                                           ['goat']             1  \n",
       "19972                                        ['yesssss']             1  \n",
       "19973                                        ['germany']             1  \n",
       "19974                                   ['worldcup2022']             1  \n",
       "\n",
       "[19975 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fifa_df = pd.read_csv(fifa)\n",
    "fifa_df_machine = pd.read_csv(fifa_machine)\n",
    "fifa_df = pd.concat([fifa_df.iloc[:rows_per_datasets], fifa_df_machine.iloc[:rows_per_datasets]], axis=0, ignore_index=True)\n",
    "fifa_df['clean_tweet'] = fifa_df['clean_tweet'].str.replace('worldcup2022', '')\n",
    "fifa_df = fifa_df.dropna()\n",
    "fifa_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 632
    },
    "id": "JC_vAUVEo6qa",
    "outputId": "a8505702-ff4a-4b31-e77a-45c4c701a578"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>Topics</th>\n",
       "      <th>Human_generated</th>\n",
       "      <th>count_url</th>\n",
       "      <th>count_emoji</th>\n",
       "      <th>count_profile</th>\n",
       "      <th>clean_tweet_Length</th>\n",
       "      <th>Tweet_Length</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>tokenize_clean_tweet</th>\n",
       "      <th>token_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>look i just need to say this right now i do no...</td>\n",
       "      <td>Game</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>280</td>\n",
       "      <td>280</td>\n",
       "      <td>Look I just need to say this right now\\nI dont...</td>\n",
       "      <td>['look', 'i', 'just', 'need', 'to', 'say', 'th...</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i m just go to say it since i feel the need to...</td>\n",
       "      <td>Game</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>267</td>\n",
       "      <td>267</td>\n",
       "      <td>I'm just gonna say it since I feel the need to...</td>\n",
       "      <td>['i', 'm', 'just', 'go', 'to', 'say', 'it', 's...</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>just give nick a whole lecture on game of thro...</td>\n",
       "      <td>Game</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>268</td>\n",
       "      <td>268</td>\n",
       "      <td>Just gave nick a whole lecture on Game of Thro...</td>\n",
       "      <td>['just', 'give', 'nick', 'a', 'whole', 'lectur...</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>z what do you think be next c i want to wake u...</td>\n",
       "      <td>Game</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>276</td>\n",
       "      <td>276</td>\n",
       "      <td>Z- what do you think is next\\nC- I want to wak...</td>\n",
       "      <td>['z', 'what', 'do', 'you', 'think', 'be', 'nex...</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>can you all tell i why you all hate season 8 g...</td>\n",
       "      <td>Game</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>269</td>\n",
       "      <td>269</td>\n",
       "      <td>Can yall tell me why yall hated season 8 game ...</td>\n",
       "      <td>['can', 'you', 'all', 'tell', 'i', 'why', 'you...</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>cersei need notch like seriously wait day voic...</td>\n",
       "      <td>Game</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>Cersei needs to be taken down a notch like ser...</td>\n",
       "      <td>['cersei', 'need', 'notch', 'like', 'seriously...</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>feel way tackle game throne book start slow ch...</td>\n",
       "      <td>Game</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>181</td>\n",
       "      <td>192</td>\n",
       "      <td>@kmcmac74 I felt the same way until I tackled ...</td>\n",
       "      <td>['feel', 'way', 'tackle', 'game', 'throne', 'b...</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>yo check petition game throne season 8 redo th...</td>\n",
       "      <td>Game</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>195</td>\n",
       "      <td>199</td>\n",
       "      <td>Yo @HBO just checked out this petition for a G...</td>\n",
       "      <td>['yo', 'check', 'petition', 'game', 'throne', ...</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>remember barne noble shut 2010 meet grrm book ...</td>\n",
       "      <td>Game</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>214</td>\n",
       "      <td>Remember when Barnes and Noble shut down in 20...</td>\n",
       "      <td>['remember', 'barne', 'noble', 'shut', '2010',...</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>talk hope taylor swift drop game throne inspo ...</td>\n",
       "      <td>Game</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "      <td>191</td>\n",
       "      <td>Can we just talk about how much I was hoping T...</td>\n",
       "      <td>['talk', 'hope', 'taylor', 'swift', 'drop', 'g...</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows √ó 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             clean_tweet Topics  \\\n",
       "0      look i just need to say this right now i do no...   Game   \n",
       "1      i m just go to say it since i feel the need to...   Game   \n",
       "2      just give nick a whole lecture on game of thro...   Game   \n",
       "3      z what do you think be next c i want to wake u...   Game   \n",
       "4      can you all tell i why you all hate season 8 g...   Game   \n",
       "...                                                  ...    ...   \n",
       "19995  cersei need notch like seriously wait day voic...   Game   \n",
       "19996  feel way tackle game throne book start slow ch...   Game   \n",
       "19997  yo check petition game throne season 8 redo th...   Game   \n",
       "19998  remember barne noble shut 2010 meet grrm book ...   Game   \n",
       "19999  talk hope taylor swift drop game throne inspo ...   Game   \n",
       "\n",
       "       Human_generated  count_url  count_emoji  count_profile  \\\n",
       "0                    1          0            0              0   \n",
       "1                    1          0            0              0   \n",
       "2                    1          0            0              0   \n",
       "3                    1          0            0              0   \n",
       "4                    1          0            0              0   \n",
       "...                ...        ...          ...            ...   \n",
       "19995                0          0            0              0   \n",
       "19996                0          0            0              1   \n",
       "19997                0          0            0              1   \n",
       "19998                0          0            0              0   \n",
       "19999                0          0            0              0   \n",
       "\n",
       "       clean_tweet_Length  Tweet_Length  \\\n",
       "0                     280           280   \n",
       "1                     267           267   \n",
       "2                     268           268   \n",
       "3                     276           276   \n",
       "4                     269           269   \n",
       "...                   ...           ...   \n",
       "19995                 200           200   \n",
       "19996                 181           192   \n",
       "19997                 195           199   \n",
       "19998                 214           214   \n",
       "19999                 191           191   \n",
       "\n",
       "                                                   Tweet  \\\n",
       "0      Look I just need to say this right now\\nI dont...   \n",
       "1      I'm just gonna say it since I feel the need to...   \n",
       "2      Just gave nick a whole lecture on Game of Thro...   \n",
       "3      Z- what do you think is next\\nC- I want to wak...   \n",
       "4      Can yall tell me why yall hated season 8 game ...   \n",
       "...                                                  ...   \n",
       "19995  Cersei needs to be taken down a notch like ser...   \n",
       "19996  @kmcmac74 I felt the same way until I tackled ...   \n",
       "19997  Yo @HBO just checked out this petition for a G...   \n",
       "19998  Remember when Barnes and Noble shut down in 20...   \n",
       "19999  Can we just talk about how much I was hoping T...   \n",
       "\n",
       "                                    tokenize_clean_tweet token_length  \n",
       "0      ['look', 'i', 'just', 'need', 'to', 'say', 'th...           67  \n",
       "1      ['i', 'm', 'just', 'go', 'to', 'say', 'it', 's...           65  \n",
       "2      ['just', 'give', 'nick', 'a', 'whole', 'lectur...           65  \n",
       "3      ['z', 'what', 'do', 'you', 'think', 'be', 'nex...           63  \n",
       "4      ['can', 'you', 'all', 'tell', 'i', 'why', 'you...           63  \n",
       "...                                                  ...          ...  \n",
       "19995  ['cersei', 'need', 'notch', 'like', 'seriously...           41  \n",
       "19996  ['feel', 'way', 'tackle', 'game', 'throne', 'b...           41  \n",
       "19997  ['yo', 'check', 'petition', 'game', 'throne', ...           41  \n",
       "19998  ['remember', 'barne', 'noble', 'shut', '2010',...           41  \n",
       "19999  ['talk', 'hope', 'taylor', 'swift', 'drop', 'g...           41  \n",
       "\n",
       "[20000 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_of_t_df = pd.read_csv(g_of_t)\n",
    "g_of_t_df_machine = pd.read_csv(g_of_t_machine)\n",
    "g_of_t_df_machine = g_of_t_df_machine.iloc[:, :11]\n",
    "g_of_t_df = pd.concat([g_of_t_df.iloc[:rows_per_datasets], g_of_t_df_machine.iloc[:rows_per_datasets]], axis=0, ignore_index=True)\n",
    "g_of_t_df = g_of_t_df.dropna()\n",
    "g_of_t_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 684
    },
    "id": "pX5TDtWOo7C7",
    "outputId": "f2372c5b-a22a-4ab8-b8a8-e52b4ef92224"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>Topics</th>\n",
       "      <th>Human_generated</th>\n",
       "      <th>count_url</th>\n",
       "      <th>count_emoji</th>\n",
       "      <th>count_profile</th>\n",
       "      <th>clean_tweet_Length</th>\n",
       "      <th>Tweet_Length</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>tokenize_clean_tweet</th>\n",
       "      <th>token_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i m proud to be a hispanic american i study an...</td>\n",
       "      <td>Election</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>275</td>\n",
       "      <td>300</td>\n",
       "      <td>@Alon2T @realDonaldTrump Im proud to be a hisp...</td>\n",
       "      <td>['i', 'm', 'proud', 'to', 'be', 'a', 'hispanic...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>do i want  to win pa yes do i believe he ll wi...</td>\n",
       "      <td>Election</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>265</td>\n",
       "      <td>265</td>\n",
       "      <td>Do I want #Biden to win PA yes Do I believe he...</td>\n",
       "      <td>['do', 'i', 'want', 'biden', 'to', 'win', 'pa'...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i m sincerely an utterly embarrassed to be an ...</td>\n",
       "      <td>Election</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>280</td>\n",
       "      <td>298</td>\n",
       "      <td>I'm sincerely an utterly embarrassed to be an ...</td>\n",
       "      <td>['i', 'm', 'sincerely', 'an', 'utterly', 'emba...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i m proud to be a hispanic american i study an...</td>\n",
       "      <td>Election</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>276</td>\n",
       "      <td>301</td>\n",
       "      <td>@charliekirk11 @cracosal I'm proud to be a his...</td>\n",
       "      <td>['i', 'm', 'proud', 'to', 'be', 'a', 'hispanic...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>come amp listen to a story bout a man name don...</td>\n",
       "      <td>Election</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>283</td>\n",
       "      <td>301</td>\n",
       "      <td>Come &amp;amp; listen to a story 'bout a man named...</td>\n",
       "      <td>['come', 'amp', 'listen', 'to', 'a', 'story', ...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19891</th>\n",
       "      <td></td>\n",
       "      <td>Election</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>@leandroruschel #Trump</td>\n",
       "      <td>['trump']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19892</th>\n",
       "      <td>yendo</td>\n",
       "      <td>Election</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>@zaynmalik yendo</td>\n",
       "      <td>['yendo']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19893</th>\n",
       "      <td></td>\n",
       "      <td>Election</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "      <td>ŸÖŸÜ ÿ™ŸÑŸà€åÿ≤€åŸàŸÜ ŸÜÿØÿßÿ±ŸÖ ŸàŸÑ€å ÿÆÿßŸÜŸàÿßÿØŸá ŸÖŸÜ ⁄©ÿ≥€å ÿ™ŸÑŸà€åÿ≤€åŸàŸÜ ...</td>\n",
       "      <td>['trump']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19894</th>\n",
       "      <td></td>\n",
       "      <td>Election</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>159</td>\n",
       "      <td>–ù–∞ –æ–≤–æ—ò –º–∞–ø–∏ –≤–∏–¥–∏–º–æ –¥–∞ —Ä–µ–ø—É–±–ª–∏–∫–∞–Ω—Ü–∏ –≥–æ—Ç–æ–≤–æ —É –ø...</td>\n",
       "      <td>['trump']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19895</th>\n",
       "      <td>joe</td>\n",
       "      <td>Election</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>#joebiden</td>\n",
       "      <td>['joebiden']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19896 rows √ó 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             clean_tweet    Topics  \\\n",
       "0      i m proud to be a hispanic american i study an...  Election   \n",
       "1      do i want  to win pa yes do i believe he ll wi...  Election   \n",
       "2      i m sincerely an utterly embarrassed to be an ...  Election   \n",
       "3      i m proud to be a hispanic american i study an...  Election   \n",
       "4      come amp listen to a story bout a man name don...  Election   \n",
       "...                                                  ...       ...   \n",
       "19891                                                     Election   \n",
       "19892                                              yendo  Election   \n",
       "19893                                                     Election   \n",
       "19894                                                     Election   \n",
       "19895                                                joe  Election   \n",
       "\n",
       "       Human_generated  count_url  count_emoji  count_profile  \\\n",
       "0                  1.0          0            0              2   \n",
       "1                  1.0          0            0              0   \n",
       "2                  1.0          1            0              0   \n",
       "3                  1.0          0            0              2   \n",
       "4                  1.0          1            0              0   \n",
       "...                ...        ...          ...            ...   \n",
       "19891              0.0          0            0              1   \n",
       "19892              0.0          0            0              1   \n",
       "19893              0.0          0            0              0   \n",
       "19894              0.0          1            0              0   \n",
       "19895              0.0          0            0              0   \n",
       "\n",
       "       clean_tweet_Length  Tweet_Length  \\\n",
       "0                     275           300   \n",
       "1                     265           265   \n",
       "2                     280           298   \n",
       "3                     276           301   \n",
       "4                     283           301   \n",
       "...                   ...           ...   \n",
       "19891                   6            22   \n",
       "19892                   5            17   \n",
       "19893                 155           155   \n",
       "19894                 138           159   \n",
       "19895                   9            10   \n",
       "\n",
       "                                                   Tweet  \\\n",
       "0      @Alon2T @realDonaldTrump Im proud to be a hisp...   \n",
       "1      Do I want #Biden to win PA yes Do I believe he...   \n",
       "2      I'm sincerely an utterly embarrassed to be an ...   \n",
       "3      @charliekirk11 @cracosal I'm proud to be a his...   \n",
       "4      Come &amp; listen to a story 'bout a man named...   \n",
       "...                                                  ...   \n",
       "19891                             @leandroruschel #Trump   \n",
       "19892                                  @zaynmalik yendo    \n",
       "19893  ŸÖŸÜ ÿ™ŸÑŸà€åÿ≤€åŸàŸÜ ŸÜÿØÿßÿ±ŸÖ ŸàŸÑ€å ÿÆÿßŸÜŸàÿßÿØŸá ŸÖŸÜ ⁄©ÿ≥€å ÿ™ŸÑŸà€åÿ≤€åŸàŸÜ ...   \n",
       "19894  –ù–∞ –æ–≤–æ—ò –º–∞–ø–∏ –≤–∏–¥–∏–º–æ –¥–∞ —Ä–µ–ø—É–±–ª–∏–∫–∞–Ω—Ü–∏ –≥–æ—Ç–æ–≤–æ —É –ø...   \n",
       "19895                                         #joebiden    \n",
       "\n",
       "                                    tokenize_clean_tweet  token_length  \n",
       "0      ['i', 'm', 'proud', 'to', 'be', 'a', 'hispanic...            61  \n",
       "1      ['do', 'i', 'want', 'biden', 'to', 'win', 'pa'...            61  \n",
       "2      ['i', 'm', 'sincerely', 'an', 'utterly', 'emba...            61  \n",
       "3      ['i', 'm', 'proud', 'to', 'be', 'a', 'hispanic...            61  \n",
       "4      ['come', 'amp', 'listen', 'to', 'a', 'story', ...            60  \n",
       "...                                                  ...           ...  \n",
       "19891                                          ['trump']             1  \n",
       "19892                                          ['yendo']             1  \n",
       "19893                                          ['trump']             1  \n",
       "19894                                          ['trump']             1  \n",
       "19895                                       ['joebiden']             1  \n",
       "\n",
       "[19896 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "election_df = pd.read_csv(election)\n",
    "election_df_machine = pd.read_csv(election_machine)\n",
    "election_df = pd.concat([election_df.iloc[:rows_per_datasets], election_df_machine.iloc[:rows_per_datasets]], axis=0, ignore_index=True)\n",
    "election_df['clean_tweet'] = election_df['clean_tweet'].str.replace('trump', '')\n",
    "election_df['clean_tweet'] = election_df['clean_tweet'].str.replace('biden', '')\n",
    "election_df['clean_tweet'] = election_df['clean_tweet'].str.replace('joebiden', '')\n",
    "election_df['clean_tweet'] = election_df['clean_tweet'].str.replace('url', '')\n",
    "election_df = election_df.dropna()\n",
    "election_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 771
    },
    "id": "YiKJqNORCNZJ",
    "outputId": "a550a767-3450-43c5-cb52-cbb9591be1de"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>Topics</th>\n",
       "      <th>Human_generated</th>\n",
       "      <th>count_url</th>\n",
       "      <th>count_emoji</th>\n",
       "      <th>count_profile</th>\n",
       "      <th>clean_tweet_Length</th>\n",
       "      <th>Tweet_Length</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>tokenize_clean_tweet</th>\n",
       "      <th>token_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45022</th>\n",
       "      <td>view this view link joe bobulinski creepy kiss...</td>\n",
       "      <td>Election</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>162</td>\n",
       "      <td>View this #view #link #JoeBiden #Bobulinski #c...</td>\n",
       "      <td>['view', 'this', 'view', 'link', 'joebiden', '...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38281</th>\n",
       "      <td>catch late episode game throne shake believe h...</td>\n",
       "      <td>Game</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>141</td>\n",
       "      <td>Just caught up on the latest episode of Game o...</td>\n",
       "      <td>['catch', 'late', 'episode', 'game', 'throne',...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6446</th>\n",
       "      <td>offside qatar live up to the corruption allega...</td>\n",
       "      <td>Fifa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>Offside‚Ä¶ Qatar living up to the corruption all...</td>\n",
       "      <td>['offside', 'qatar', 'live', 'up', 'to', 'the'...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21115</th>\n",
       "      <td>to all those people complain about game of thr...</td>\n",
       "      <td>Game</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>261</td>\n",
       "      <td>261</td>\n",
       "      <td>To all those people complaining about game of ...</td>\n",
       "      <td>['to', 'all', 'those', 'people', 'complain', '...</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53699</th>\n",
       "      <td>can t believe people would vandalize a jewish ...</td>\n",
       "      <td>Election</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>122</td>\n",
       "      <td>#Can't believe people would vandalize a Jewish...</td>\n",
       "      <td>['can', 't', 'believe', 'people', 'would', 'va...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41281</th>\n",
       "      <td>do not let up do not be discourage abt long li...</td>\n",
       "      <td>Election</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "      <td>267</td>\n",
       "      <td>@ChristianWalk1r DO NOT LET UP Do not be disco...</td>\n",
       "      <td>['do', 'not', 'let', 'up', 'do', 'not', 'be', ...</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54352</th>\n",
       "      <td>make move in the forex market like a boss chec...</td>\n",
       "      <td>Election</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>109</td>\n",
       "      <td>Making moves in the forex market like a boss üí™...</td>\n",
       "      <td>['make', 'move', 'in', 'the', 'forex', 'market...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20450</th>\n",
       "      <td>this random guy join my overwatch group and we...</td>\n",
       "      <td>Game</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>243</td>\n",
       "      <td>245</td>\n",
       "      <td>This random guy joins my overwatch group and w...</td>\n",
       "      <td>['this', 'random', 'guy', 'join', 'my', 'overw...</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>a disappointing article that ignore the spurio...</td>\n",
       "      <td>Fifa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>258</td>\n",
       "      <td>275</td>\n",
       "      <td>A disappointing article that ignores the spuri...</td>\n",
       "      <td>['a', 'disappointing', 'article', 'that', 'ign...</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34752</th>\n",
       "      <td>extra ex hook game throne surprise epic decide...</td>\n",
       "      <td>Game</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>Not to be extra but my ex got me hooked on Gam...</td>\n",
       "      <td>['extra', 'ex', 'hook', 'game', 'throne', 'sur...</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59871 rows √ó 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             clean_tweet    Topics  \\\n",
       "45022  view this view link joe bobulinski creepy kiss...  Election   \n",
       "38281  catch late episode game throne shake believe h...      Game   \n",
       "6446   offside qatar live up to the corruption allega...      Fifa   \n",
       "21115  to all those people complain about game of thr...      Game   \n",
       "53699  can t believe people would vandalize a jewish ...  Election   \n",
       "...                                                  ...       ...   \n",
       "41281  do not let up do not be discourage abt long li...  Election   \n",
       "54352  make move in the forex market like a boss chec...  Election   \n",
       "20450  this random guy join my overwatch group and we...      Game   \n",
       "931    a disappointing article that ignore the spurio...      Fifa   \n",
       "34752  extra ex hook game throne surprise epic decide...      Game   \n",
       "\n",
       "       Human_generated  count_url  count_emoji  count_profile  \\\n",
       "45022              1.0          1            0              0   \n",
       "38281              0.0          0            0              0   \n",
       "6446               1.0          0            1              0   \n",
       "21115              1.0          0            0              0   \n",
       "53699              0.0          0            1              0   \n",
       "...                ...        ...          ...            ...   \n",
       "41281              1.0          0            0              1   \n",
       "54352              0.0          0            1              0   \n",
       "20450              1.0          0            1              0   \n",
       "931                1.0          0            0              1   \n",
       "34752              0.0          0            0              0   \n",
       "\n",
       "       clean_tweet_Length  Tweet_Length  \\\n",
       "45022                 144           162   \n",
       "38281                 141           141   \n",
       "6446                   90            90   \n",
       "21115                 261           261   \n",
       "53699                 117           122   \n",
       "...                   ...           ...   \n",
       "41281                 250           267   \n",
       "54352                 109           109   \n",
       "20450                 243           245   \n",
       "931                   258           275   \n",
       "34752                 159           159   \n",
       "\n",
       "                                                   Tweet  \\\n",
       "45022  View this #view #link #JoeBiden #Bobulinski #c...   \n",
       "38281  Just caught up on the latest episode of Game o...   \n",
       "6446   Offside‚Ä¶ Qatar living up to the corruption all...   \n",
       "21115  To all those people complaining about game of ...   \n",
       "53699  #Can't believe people would vandalize a Jewish...   \n",
       "...                                                  ...   \n",
       "41281  @ChristianWalk1r DO NOT LET UP Do not be disco...   \n",
       "54352  Making moves in the forex market like a boss üí™...   \n",
       "20450  This random guy joins my overwatch group and w...   \n",
       "931    A disappointing article that ignores the spuri...   \n",
       "34752  Not to be extra but my ex got me hooked on Gam...   \n",
       "\n",
       "                                    tokenize_clean_tweet token_length  \n",
       "45022  ['view', 'this', 'view', 'link', 'joebiden', '...           20  \n",
       "38281  ['catch', 'late', 'episode', 'game', 'throne',...           26  \n",
       "6446   ['offside', 'qatar', 'live', 'up', 'to', 'the'...           11  \n",
       "21115  ['to', 'all', 'those', 'people', 'complain', '...           52  \n",
       "53699  ['can', 't', 'believe', 'people', 'would', 'va...           21  \n",
       "...                                                  ...          ...  \n",
       "41281  ['do', 'not', 'let', 'up', 'do', 'not', 'be', ...           41  \n",
       "54352  ['make', 'move', 'in', 'the', 'forex', 'market...           19  \n",
       "20450  ['this', 'random', 'guy', 'join', 'my', 'overw...           55  \n",
       "931    ['a', 'disappointing', 'article', 'that', 'ign...           37  \n",
       "34752  ['extra', 'ex', 'hook', 'game', 'throne', 'sur...           36  \n",
       "\n",
       "[59871 rows x 11 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge all the dataframes\n",
    "all_df = pd.concat([fifa_df, g_of_t_df, election_df], ignore_index=True)\n",
    "all_df = all_df.sample(frac=1, random_state=41)\n",
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "lUKV2rQqAUqu"
   },
   "outputs": [],
   "source": [
    "def convert_to_csv_string(string_list):\n",
    "    list_representation = literal_eval(string_list)\n",
    "    return ' '.join(map(str, list_representation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "4ubOIIxNksto"
   },
   "outputs": [],
   "source": [
    "# Train svm model using clean tweets, evaluate the performance and get feature importances\n",
    "def SVM_clean_tweets(features, target):\n",
    "    X = features\n",
    "    y = target\n",
    "\n",
    "    # Initialize TF-IDF Vectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # Initialize SVM model\n",
    "    svm_model = svm.SVC(kernel = 'sigmoid', C = 1.0, class_weight = 'balanced')\n",
    "\n",
    "    # Initialize KFold\n",
    "    kf = KFold(n_splits = 5, shuffle = True, random_state = 5)\n",
    "\n",
    "    accuracies = []\n",
    "\n",
    "    for fold_idx, (train_index, test_index) in enumerate(kf.split(X), 1):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # TF-IDF Vectorization\n",
    "        X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "        X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "        # Train SVM model\n",
    "        svm_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred = svm_model.predict(X_test_tfidf)\n",
    "\n",
    "        # Evaluate performance\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "        # Print classification report for the fold\n",
    "        print(f\"\\nClassification Report (fold {fold_idx}):\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "    # Calculate and print average accuracy across all folds\n",
    "    avg_accuracy = sum(accuracies) / len(accuracies)\n",
    "    print(\"\\nAverage Accuracy:\", avg_accuracy)\n",
    "    return svm_model, avg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper function to use multithreading in svm for modeling acceleration\n",
    "def train_and_predict_svm(train_index, test_index, X_text, X_numerical, y, svm_model):\n",
    "    X_train_text, X_test_text = X_text[train_index], X_text[test_index]\n",
    "    X_train_numerical, X_test_numerical = X_numerical.iloc[train_index], X_numerical.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Initialize TF-IDF Vectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # TF-IDF Vectorization for text data\n",
    "    X_train_text_tfidf = vectorizer.fit_transform(X_train_text)\n",
    "    X_test_text_tfidf = vectorizer.transform(X_test_text)\n",
    "\n",
    "    # Combine text and numerical features\n",
    "    X_train_combined = hstack([X_train_text_tfidf, X_train_numerical.values])\n",
    "    X_test_combined = hstack([X_test_text_tfidf, X_test_numerical.values])\n",
    "\n",
    "    # Train the SVM model\n",
    "    svm_model.fit(X_train_combined, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = svm_model.predict(X_test_combined)\n",
    "\n",
    "    # Evaluate performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy, y_test, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_tweet_emoji_profile(features, target):\n",
    "    X_text = features['clean_tweet']\n",
    "    X_numerical = features[['count_emoji', 'count_profile']]\n",
    "    y = target\n",
    "\n",
    "    # Initialize SVM model\n",
    "    svm_model = svm.SVC(kernel='sigmoid', C=1.0)\n",
    "\n",
    "    # Initialize KFold\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    accuracies = []\n",
    "\n",
    "    # Create a pool of worker processes\n",
    "    num_cores = 32\n",
    "    pool = Pool(processes=num_cores)\n",
    "\n",
    "    # Iterate over each fold\n",
    "    for fold_idx, (train_index, test_index) in enumerate(kf.split(X_text), 1):\n",
    "        # Perform parallel training and inference\n",
    "        results = pool.starmap(train_and_predict_svm, [(train_index, test_index, X_text, X_numerical, y, svm_model)])\n",
    "\n",
    "        # Collect results\n",
    "        for accuracy, y_test, y_pred in results:\n",
    "            accuracies.append(accuracy)\n",
    "            # Print classification report for the fold\n",
    "            print(f\"\\nClassification Report (fold {fold_idx}):\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "    # Close the pool of worker processes\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    # Calculate and print average accuracy across all folds\n",
    "    avg_accuracy = sum(accuracies) / len(accuracies)\n",
    "    print(\"\\nAverage Accuracy:\", avg_accuracy)\n",
    "    return svm_model, avg_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "sc1j7mR3WfjC"
   },
   "outputs": [],
   "source": [
    "def SVM_emoji_profile_count(features, target):\n",
    "    numerical_columns = ['count_emoji', 'count_profile']\n",
    "    X = features[numerical_columns]\n",
    "    y = target\n",
    "\n",
    "    # Initialize SVM model\n",
    "    svm_model = svm.SVC(kernel = 'sigmoid', C = 1.0)\n",
    "\n",
    "    # Initialize KFold\n",
    "    kf = KFold(n_splits = 5, shuffle = True, random_state = 5)\n",
    "\n",
    "    accuracies = []\n",
    "\n",
    "    for fold_idx, (train_index, test_index) in enumerate(kf.split(X), 1):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Train the SVM model\n",
    "        svm_model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred = svm_model.predict(X_test)\n",
    "\n",
    "        # Evaluate performance\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "        # Print classification report for the fold\n",
    "        print(f\"\\nClassification Report (fold {fold_idx}):\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "    # Calculate and print average accuracy across all folds\n",
    "    avg_accuracy = sum(accuracies) / len(accuracies)\n",
    "    print(\"\\nAverage Accuracy:\", avg_accuracy)\n",
    "    return svm_model, avg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "NSR_lgaulcON"
   },
   "outputs": [],
   "source": [
    "# Train random forest model using clean tweets, evaluate the performance and get feature importances\n",
    "def RF_clean_tweets(features, target):\n",
    "    X = features\n",
    "    y = target\n",
    "\n",
    "    # Initialize TF-IDF Vectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # Initialize Random Forest model\n",
    "    rf_model = RandomForestClassifier(n_estimators = 100, random_state = 5)\n",
    "\n",
    "    # Initialize KFold\n",
    "    kf = KFold(n_splits = 5, shuffle = True, random_state = 5)\n",
    "\n",
    "    accuracies = []\n",
    "\n",
    "    for fold_idx, (train_index, test_index) in enumerate(kf.split(X), 1):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # TF-IDF Vectorization\n",
    "        X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "        X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "        # Train rf model\n",
    "        rf_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred = rf_model.predict(X_test_tfidf)\n",
    "\n",
    "        # Evaluate performance\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "        # Print classification report for the fold\n",
    "        print(f\"\\nClassification Report (fold {fold_idx}):\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "    # Calculate and print average accuracy across all folds\n",
    "    avg_accuracy = sum(accuracies) / len(accuracies)\n",
    "    print(\"\\nAverage Accuracy:\", avg_accuracy)\n",
    "\n",
    "    # Get feature names from the vectorizer\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    # Get feature importances from the trained model\n",
    "    feature_importances_rf = rf_model.feature_importances_\n",
    "    # Pair feature names with their importances and sort\n",
    "    feature_importances_rf = sorted(zip(feature_names, feature_importances_rf), key=lambda x: x[1], reverse=True)\n",
    "    print('Feature importance:')\n",
    "    # Print top N features and their importances\n",
    "    top_n = 10\n",
    "    for feature, importance in feature_importances_rf[:top_n]:\n",
    "        print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF_tweet_emoji_profile(features, target):\n",
    "    # Extract text data from clean tweets\n",
    "    text_columns = ['clean_tweet']\n",
    "    X_text_tfidf_list = []\n",
    "    y = target\n",
    "\n",
    "    for column in text_columns:\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        X_text_tfidf = vectorizer.fit_transform(features[column])\n",
    "        X_text_tfidf_list.append(X_text_tfidf)\n",
    "\n",
    "    # Extract emoji and profile count from the DataFrame\n",
    "    numerical_columns = ['count_emoji', 'count_profile']\n",
    "    X_numerical = features[numerical_columns]\n",
    "\n",
    "    # Combine text features with numerical features\n",
    "    X_combined = hstack([*X_text_tfidf_list, X_numerical])\n",
    "\n",
    "    # Convert to dense numpy array\n",
    "    X_combined_array = X_combined.toarray()\n",
    "\n",
    "    # Initialize Random Forest model\n",
    "    rf_model = RandomForestClassifier(n_estimators = 100, random_state = 5)\n",
    "\n",
    "    # Initialize KFold\n",
    "    kf = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "\n",
    "    accuracies = []\n",
    "\n",
    "    # Iterate over each fold\n",
    "    for fold_idx, (train_index, test_index) in enumerate(kf.split(X_combined_array), 1):\n",
    "        X_train, X_test = X_combined_array[train_index], X_combined_array[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Train the rf model\n",
    "        rf_model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred = rf_model.predict(X_test)\n",
    "\n",
    "        # Evaluate performance\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "        # Print classification report for the fold\n",
    "        print(f\"\\nClassification Report (fold {fold_idx}):\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "    # Calculate and print average accuracy across all folds\n",
    "    avg_accuracy = sum(accuracies) / len(accuracies)\n",
    "    print(\"\\nAverage Accuracy:\", avg_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "vUqbw2I8XnrV"
   },
   "outputs": [],
   "source": [
    "def RF_emoji_profile_count(features, target):\n",
    "    numerical_columns = ['count_emoji', 'count_profile']\n",
    "    X = features[numerical_columns]\n",
    "    y = target\n",
    "\n",
    "    # Initialize Random Forest model\n",
    "    rf_model = RandomForestClassifier(n_estimators = 100, random_state = 5)\n",
    "\n",
    "    # Initialize KFold\n",
    "    kf = KFold(n_splits = 5, shuffle = True, random_state = 5)\n",
    "\n",
    "    accuracies = []\n",
    "\n",
    "    for fold_idx, (train_index, test_index) in enumerate(kf.split(X), 1):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Train the rf model\n",
    "        rf_model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred = rf_model.predict(X_test)\n",
    "\n",
    "        # Evaluate performance\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "        # Print classification report for the fold\n",
    "        print(f\"\\nClassification Report (fold {fold_idx}):\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "    # Calculate and print average accuracy across all folds\n",
    "    avg_accuracy = sum(accuracies) / len(accuracies)\n",
    "    print(\"\\nAverage Accuracy:\", avg_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict_lr(train_index, test_index, X_train, y_train, X_test, y_test):\n",
    "    # Initialize Logistic Regression model\n",
    "    lr_model = LogisticRegression(max_iter=1000, random_state=5)\n",
    "\n",
    "    # Train Logistic Regression model\n",
    "    lr_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = lr_model.predict(X_test)\n",
    "\n",
    "    # Evaluate performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    coefficients = lr_model.coef_[0]\n",
    "    return accuracy, y_test, y_pred, coefficients, lr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR_clean_tweets(features, target):\n",
    "    X = features\n",
    "    y = target\n",
    "\n",
    "    # Initialize TF-IDF Vectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # Initialize KFold\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=5)\n",
    "\n",
    "    accuracies = []\n",
    "    trained_models = []\n",
    "\n",
    "    # Create a pool of worker processes\n",
    "    num_cores = 32\n",
    "    pool = Pool(processes=num_cores)\n",
    "\n",
    "    for fold_idx, (train_index, test_index) in enumerate(kf.split(X), 1):\n",
    "        X_train_tfidf, X_test_tfidf = vectorizer.fit_transform(X[train_index]), vectorizer.transform(X[test_index])\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Perform parallel training and prediction\n",
    "        results = pool.starmap(train_and_predict_lr, [(train_index, test_index, X_train_tfidf, y_train, X_test_tfidf, y_test)])\n",
    "\n",
    "        # Collect results\n",
    "        for accuracy, y_test, y_pred, coefficients, lr_model in results:\n",
    "            accuracies.append(accuracy)\n",
    "            trained_models.append(lr_model)\n",
    "\n",
    "            # Print classification report for the fold\n",
    "            print(f\"\\nClassification Report (fold {fold_idx}):\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "            \n",
    "    # Close the pool of worker processes\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    # Calculate and print average accuracy across all folds\n",
    "    avg_accuracy = sum(accuracies) / len(accuracies)\n",
    "    print(\"\\nAverage Accuracy:\", avg_accuracy)\n",
    "    # Get feature names from the vectorizer\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    # Pair feature names with their coefficients and sort by absolute value\n",
    "    feature_importances_logreg = sorted(zip(feature_names, coefficients), key=lambda x: abs(x[1]), reverse=True)\n",
    "    print('Feature importance:')\n",
    "    # Print top N features and their coefficients\n",
    "    top_n = 10\n",
    "    for feature, coef in feature_importances_logreg[:top_n]:\n",
    "        print(f\"{feature}: {coef}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR_tweet_emoji_profile(features, target):\n",
    "    # Extract text data from clean tweets\n",
    "    text_columns = ['clean_tweet']\n",
    "    X_text_tfidf_list = []\n",
    "    y = target\n",
    "\n",
    "    for column in text_columns:\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        X_text_tfidf = vectorizer.fit_transform(features[column])\n",
    "        X_text_tfidf_list.append(X_text_tfidf)\n",
    "\n",
    "    # Extract emoji and profile count from the DataFrame\n",
    "    numerical_columns = ['count_emoji', 'count_profile']\n",
    "    X_numerical = features[numerical_columns]\n",
    "\n",
    "    # Combine text features with numerical features\n",
    "    X_combined = hstack([*X_text_tfidf_list, X_numerical])\n",
    "\n",
    "    # Convert to dense numpy array\n",
    "    X_combined_array = X_combined.toarray()\n",
    "\n",
    "    # Initialize Logistic Regression model\n",
    "    lr_model = LogisticRegression(max_iter = 1000, random_state = 5)\n",
    "\n",
    "    # Initialize KFold\n",
    "    kf = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "\n",
    "    accuracies = []\n",
    "\n",
    "    # Iterate over each fold\n",
    "    for fold_idx, (train_index, test_index) in enumerate(kf.split(X_combined_array), 1):\n",
    "        X_train, X_test = X_combined_array[train_index], X_combined_array[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Train the lr model\n",
    "        lr_model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred = lr_model.predict(X_test)\n",
    "\n",
    "        # Evaluate performance\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "        # Print classification report for the fold\n",
    "        print(f\"\\nClassification Report (fold {fold_idx}):\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "    # Calculate and print average accuracy across all folds\n",
    "    avg_accuracy = sum(accuracies) / len(accuracies)\n",
    "    print(\"\\nAverage Accuracy:\", avg_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "i25IVNaFYOR1"
   },
   "outputs": [],
   "source": [
    "def LR_emoji_profile_count(features, target):\n",
    "    numerical_columns = ['count_emoji', 'count_profile']\n",
    "    X = features[numerical_columns]\n",
    "    y = target\n",
    "\n",
    "    # Initialize Logistic Regression model\n",
    "    lr_model = LogisticRegression(max_iter = 1000, random_state = 5)\n",
    "\n",
    "    # Initialize KFold\n",
    "    kf = KFold(n_splits = 5, shuffle = True, random_state = 5)\n",
    "\n",
    "    accuracies = []\n",
    "\n",
    "    for fold_idx, (train_index, test_index) in enumerate(kf.split(X), 1):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Train the lr model\n",
    "        lr_model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred = lr_model.predict(X_test)\n",
    "\n",
    "        # Evaluate performance\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "        # Print classification report for the fold\n",
    "        print(f\"\\nClassification Report (fold {fold_idx}):\\n\", classification_report(y_test, y_pred, zero_division = 1))\n",
    "\n",
    "    # Calculate and print average accuracy across all folds\n",
    "    avg_accuracy = sum(accuracies) / len(accuracies)\n",
    "    print(\"\\nAverage Accuracy:\", avg_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "-sGoq-UNnraG"
   },
   "outputs": [],
   "source": [
    "# Train decision tree model using clean tweets, evaluate the performance and get feature importances\n",
    "def DT_clean_tweets(features, target):\n",
    "    X = features\n",
    "    y = target\n",
    "\n",
    "    # Initialize TF-IDF Vectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # Initialize Decision Tree model\n",
    "    dt_model = DecisionTreeClassifier(random_state = 5)\n",
    "\n",
    "    # Initialize KFold\n",
    "    kf = KFold(n_splits = 5, shuffle = True, random_state = 5)\n",
    "\n",
    "    accuracies = []\n",
    "\n",
    "    for fold_idx, (train_index, test_index) in enumerate(kf.split(X), 1):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # TF-IDF Vectorization\n",
    "        X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "        X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "        # Train dtr model\n",
    "        dt_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred = dt_model.predict(X_test_tfidf)\n",
    "\n",
    "        # Evaluate performance\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "        # Print classification report for the fold\n",
    "        print(f\"\\nClassification Report (fold {fold_idx}):\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "    # Calculate and print average accuracy across all folds\n",
    "    avg_accuracy = sum(accuracies) / len(accuracies)\n",
    "    print(\"\\nAverage Accuracy:\", avg_accuracy)\n",
    "\n",
    "    # Get feature names from the TF-IDF vectorizer\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    # Get feature importances from the trained Decision Tree model\n",
    "    feature_importances_dt = dt_model.feature_importances_\n",
    "    # Pair feature names with their importances\n",
    "    feature_importances_dt = zip(feature_names, feature_importances_dt)\n",
    "    # Sort features by their importances\n",
    "    feature_importances_dt = sorted(feature_importances_dt, key=lambda x: x[1], reverse=True)\n",
    "    print('Feature importance:')\n",
    "    # Print top N features and their importances\n",
    "    top_n = 10\n",
    "    for feature, importance in feature_importances_dt[:top_n]:\n",
    "        print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DT_tweet_emoji_profile(features, target):\n",
    "      # Extract text data from clean tweets\n",
    "    text_columns = ['clean_tweet']\n",
    "    X_text_tfidf_list = []\n",
    "    y = target\n",
    "\n",
    "    for column in text_columns:\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        X_text_tfidf = vectorizer.fit_transform(features[column])\n",
    "        X_text_tfidf_list.append(X_text_tfidf)\n",
    "\n",
    "    # Extract emoji and profile count from the DataFrame\n",
    "    numerical_columns = ['count_emoji', 'count_profile']\n",
    "    X_numerical = features[numerical_columns]\n",
    "\n",
    "    # Combine text features with numerical features\n",
    "    X_combined = hstack([*X_text_tfidf_list, X_numerical])\n",
    "\n",
    "    # Convert to dense numpy array\n",
    "    X_combined_array = X_combined.toarray()\n",
    "\n",
    "    # Initialize Decision Tree model\n",
    "    dt_model = DecisionTreeClassifier(random_state = 5)\n",
    "\n",
    "    # Initialize KFold\n",
    "    kf = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "\n",
    "    accuracies = []\n",
    "\n",
    "    # Iterate over each fold\n",
    "    for fold_idx, (train_index, test_index) in enumerate(kf.split(X_combined_array), 1):\n",
    "        X_train, X_test = X_combined_array[train_index], X_combined_array[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Train the dt model\n",
    "        dt_model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred = dt_model.predict(X_test)\n",
    "\n",
    "        # Evaluate performance\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "        # Print classification report for the fold\n",
    "        print(f\"\\nClassification Report (fold {fold_idx}):\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "    # Calculate and print average accuracy across all folds\n",
    "    avg_accuracy = sum(accuracies) / len(accuracies)\n",
    "    print(\"\\nAverage Accuracy:\", avg_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "tgSJG-0hYbJl"
   },
   "outputs": [],
   "source": [
    "def DT_emoji_profile_count(features, target):\n",
    "    numerical_columns = ['count_emoji', 'count_profile']\n",
    "    X = features[numerical_columns]\n",
    "    y = target\n",
    "\n",
    "    # Initialize Decision Tree model\n",
    "    dt_model = DecisionTreeClassifier(random_state = 5)\n",
    "\n",
    "    # Initialize KFold\n",
    "    kf = KFold(n_splits = 5, shuffle = True, random_state = 5)\n",
    "\n",
    "    accuracies = []\n",
    "\n",
    "    for fold_idx, (train_index, test_index) in enumerate(kf.split(X), 1):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Train the dt model\n",
    "        dt_model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred = dt_model.predict(X_test)\n",
    "\n",
    "        # Evaluate performance\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "        # Print classification report for the fold\n",
    "        print(f\"\\nClassification Report (fold {fold_idx}):\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "    # Calculate and print average accuracy across all folds\n",
    "    avg_accuracy = sum(accuracies) / len(accuracies)\n",
    "    print(\"\\nAverage Accuracy:\", avg_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WTRhtH88ucag"
   },
   "source": [
    "## SVM model for FIFA datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iNsYv9PyioNJ",
    "outputId": "21a5d758-a54f-4141-ff39-45a7ff36936f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (fold 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.73      0.75      2032\n",
      "           1       0.73      0.78      0.75      1963\n",
      "\n",
      "    accuracy                           0.75      3995\n",
      "   macro avg       0.75      0.75      0.75      3995\n",
      "weighted avg       0.75      0.75      0.75      3995\n",
      "\n",
      "\n",
      "Classification Report (fold 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.75      1966\n",
      "           1       0.76      0.77      0.77      2029\n",
      "\n",
      "    accuracy                           0.76      3995\n",
      "   macro avg       0.76      0.76      0.76      3995\n",
      "weighted avg       0.76      0.76      0.76      3995\n",
      "\n",
      "\n",
      "Classification Report (fold 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.72      0.74      2001\n",
      "           1       0.74      0.77      0.75      1994\n",
      "\n",
      "    accuracy                           0.75      3995\n",
      "   macro avg       0.75      0.75      0.75      3995\n",
      "weighted avg       0.75      0.75      0.75      3995\n",
      "\n",
      "\n",
      "Classification Report (fold 4):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.73      0.75      1988\n",
      "           1       0.74      0.78      0.76      2007\n",
      "\n",
      "    accuracy                           0.75      3995\n",
      "   macro avg       0.75      0.75      0.75      3995\n",
      "weighted avg       0.75      0.75      0.75      3995\n",
      "\n",
      "\n",
      "Classification Report (fold 5):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.72      0.73      1988\n",
      "           1       0.73      0.77      0.75      2007\n",
      "\n",
      "    accuracy                           0.74      3995\n",
      "   macro avg       0.74      0.74      0.74      3995\n",
      "weighted avg       0.74      0.74      0.74      3995\n",
      "\n",
      "\n",
      "Average Accuracy: 0.7510387984981226\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(SVC(class_weight='balanced', kernel='sigmoid'), 0.7510387984981226)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM_clean_tweets(fifa_df['clean_tweet'], fifa_df['Human_generated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (fold 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.56      0.58      1988\n",
      "           1       0.59      0.62      0.60      2007\n",
      "\n",
      "    accuracy                           0.59      3995\n",
      "   macro avg       0.59      0.59      0.59      3995\n",
      "weighted avg       0.59      0.59      0.59      3995\n",
      "\n",
      "\n",
      "Classification Report (fold 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.56      0.57      1972\n",
      "           1       0.58      0.60      0.59      2023\n",
      "\n",
      "    accuracy                           0.58      3995\n",
      "   macro avg       0.58      0.58      0.58      3995\n",
      "weighted avg       0.58      0.58      0.58      3995\n",
      "\n",
      "\n",
      "Classification Report (fold 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.55      0.57      2016\n",
      "           1       0.57      0.60      0.58      1979\n",
      "\n",
      "    accuracy                           0.58      3995\n",
      "   macro avg       0.58      0.58      0.58      3995\n",
      "weighted avg       0.58      0.58      0.57      3995\n",
      "\n",
      "\n",
      "Classification Report (fold 4):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.59      0.59      1962\n",
      "           1       0.60      0.60      0.60      2033\n",
      "\n",
      "    accuracy                           0.60      3995\n",
      "   macro avg       0.60      0.60      0.60      3995\n",
      "weighted avg       0.60      0.60      0.60      3995\n",
      "\n",
      "\n",
      "Classification Report (fold 5):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.64      0.67      2037\n",
      "           1       0.65      0.70      0.68      1958\n",
      "\n",
      "    accuracy                           0.67      3995\n",
      "   macro avg       0.67      0.67      0.67      3995\n",
      "weighted avg       0.67      0.67      0.67      3995\n",
      "\n",
      "\n",
      "Average Accuracy: 0.6022027534418022\n"
     ]
    }
   ],
   "source": [
    "SVM_tweet_emoji_profile(fifa_df, fifa_df['Human_generated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m8ZzNNmnXDMk",
    "outputId": "4c0c7892-657f-41cb-ea5d-c8a69bb4e968"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (fold 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.41      0.50      2032\n",
      "           1       0.56      0.76      0.64      1963\n",
      "\n",
      "    accuracy                           0.58      3995\n",
      "   macro avg       0.60      0.59      0.57      3995\n",
      "weighted avg       0.60      0.58      0.57      3995\n",
      "\n",
      "\n",
      "Classification Report (fold 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.71      0.57      1966\n",
      "           1       0.45      0.24      0.31      2029\n",
      "\n",
      "    accuracy                           0.47      3995\n",
      "   macro avg       0.46      0.47      0.44      3995\n",
      "weighted avg       0.46      0.47      0.44      3995\n",
      "\n",
      "\n",
      "Classification Report (fold 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.71      0.57      2001\n",
      "           1       0.43      0.22      0.29      1994\n",
      "\n",
      "    accuracy                           0.47      3995\n",
      "   macro avg       0.45      0.46      0.43      3995\n",
      "weighted avg       0.45      0.47      0.43      3995\n",
      "\n",
      "\n",
      "Classification Report (fold 4):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.40      0.49      1988\n",
      "           1       0.57      0.77      0.65      2007\n",
      "\n",
      "    accuracy                           0.59      3995\n",
      "   macro avg       0.60      0.59      0.57      3995\n",
      "weighted avg       0.60      0.59      0.57      3995\n",
      "\n",
      "\n",
      "Classification Report (fold 5):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.71      0.57      1988\n",
      "           1       0.44      0.23      0.30      2007\n",
      "\n",
      "    accuracy                           0.47      3995\n",
      "   macro avg       0.46      0.47      0.43      3995\n",
      "weighted avg       0.46      0.47      0.43      3995\n",
      "\n",
      "\n",
      "Average Accuracy: 0.5141927409261577\n"
     ]
    }
   ],
   "source": [
    "SVM_emoji_profile_count(fifa_df, fifa_df['Human_generated'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5krcTjaZfXao"
   },
   "source": [
    "## Random forest model for FIFA datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z_l6n8uofWxT",
    "outputId": "f33f3a48-9b6c-4266-952c-feca596fdccc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (fold 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.77      0.74      2032\n",
      "           1       0.74      0.69      0.71      1963\n",
      "\n",
      "    accuracy                           0.73      3995\n",
      "   macro avg       0.73      0.73      0.73      3995\n",
      "weighted avg       0.73      0.73      0.73      3995\n",
      "\n",
      "\n",
      "Classification Report (fold 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.77      0.74      1966\n",
      "           1       0.76      0.70      0.73      2029\n",
      "\n",
      "    accuracy                           0.73      3995\n",
      "   macro avg       0.73      0.73      0.73      3995\n",
      "weighted avg       0.73      0.73      0.73      3995\n",
      "\n",
      "\n",
      "Classification Report (fold 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.77      0.73      2001\n",
      "           1       0.74      0.68      0.71      1994\n",
      "\n",
      "    accuracy                           0.72      3995\n",
      "   macro avg       0.72      0.72      0.72      3995\n",
      "weighted avg       0.72      0.72      0.72      3995\n",
      "\n",
      "\n",
      "Classification Report (fold 4):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.76      0.74      1988\n",
      "           1       0.75      0.71      0.73      2007\n",
      "\n",
      "    accuracy                           0.74      3995\n",
      "   macro avg       0.74      0.74      0.74      3995\n",
      "weighted avg       0.74      0.74      0.74      3995\n",
      "\n",
      "\n",
      "Classification Report (fold 5):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.73      0.72      1988\n",
      "           1       0.73      0.70      0.71      2007\n",
      "\n",
      "    accuracy                           0.72      3995\n",
      "   macro avg       0.72      0.72      0.72      3995\n",
      "weighted avg       0.72      0.72      0.72      3995\n",
      "\n",
      "\n",
      "Average Accuracy: 0.7274593241551941\n",
      "Feature importance:\n",
      "the: 0.01679585980415899\n",
      "for: 0.01588251365204891\n",
      "be: 0.011943271192686853\n",
      "let: 0.011642856551155817\n",
      "qatar: 0.011126956366260977\n",
      "worldcup: 0.008805337903688863\n",
      "can: 0.008737598503096754\n",
      "just: 0.008672010656810721\n",
      "of: 0.008476701297763945\n",
      "to: 0.008373513973494843\n"
     ]
    }
   ],
   "source": [
    "RF_clean_tweets(fifa_df['clean_tweet'], fifa_df['Human_generated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (fold 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.75      0.74      1988\n",
      "           1       0.74      0.73      0.74      2007\n",
      "\n",
      "    accuracy                           0.74      3995\n",
      "   macro avg       0.74      0.74      0.74      3995\n",
      "weighted avg       0.74      0.74      0.74      3995\n",
      "\n",
      "\n",
      "Classification Report (fold 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.78      0.75      1972\n",
      "           1       0.77      0.71      0.74      2023\n",
      "\n",
      "    accuracy                           0.75      3995\n",
      "   macro avg       0.75      0.75      0.75      3995\n",
      "weighted avg       0.75      0.75      0.75      3995\n",
      "\n",
      "\n",
      "Classification Report (fold 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.75      0.74      2016\n",
      "           1       0.74      0.72      0.73      1979\n",
      "\n",
      "    accuracy                           0.74      3995\n",
      "   macro avg       0.74      0.73      0.73      3995\n",
      "weighted avg       0.74      0.74      0.74      3995\n",
      "\n",
      "\n",
      "Classification Report (fold 4):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73      1962\n",
      "           1       0.74      0.73      0.73      2033\n",
      "\n",
      "    accuracy                           0.73      3995\n",
      "   macro avg       0.73      0.73      0.73      3995\n",
      "weighted avg       0.73      0.73      0.73      3995\n",
      "\n",
      "\n",
      "Classification Report (fold 5):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.73      0.74      2037\n",
      "           1       0.73      0.74      0.74      1958\n",
      "\n",
      "    accuracy                           0.74      3995\n",
      "   macro avg       0.74      0.74      0.74      3995\n",
      "weighted avg       0.74      0.74      0.74      3995\n",
      "\n",
      "\n",
      "Average Accuracy: 0.7383729662077597\n"
     ]
    }
   ],
   "source": [
    "RF_tweet_emoji_profile(fifa_df, fifa_df['Human_generated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7eXz3xajX34F",
    "outputId": "2f335630-2134-4910-e962-a1d015e0c217"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (fold 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.40      0.50      2032\n",
      "           1       0.56      0.79      0.66      1963\n",
      "\n",
      "    accuracy                           0.59      3995\n",
      "   macro avg       0.61      0.60      0.58      3995\n",
      "weighted avg       0.61      0.59      0.58      3995\n",
      "\n",
      "\n",
      "Classification Report (fold 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.42      0.50      1966\n",
      "           1       0.57      0.74      0.64      2029\n",
      "\n",
      "    accuracy                           0.58      3995\n",
      "   macro avg       0.59      0.58      0.57      3995\n",
      "weighted avg       0.59      0.58      0.57      3995\n",
      "\n",
      "\n",
      "Classification Report (fold 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.43      0.52      2001\n",
      "           1       0.57      0.75      0.65      1994\n",
      "\n",
      "    accuracy                           0.59      3995\n",
      "   macro avg       0.60      0.59      0.58      3995\n",
      "weighted avg       0.60      0.59      0.58      3995\n",
      "\n",
      "\n",
      "Classification Report (fold 4):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.43      0.52      1988\n",
      "           1       0.58      0.77      0.66      2007\n",
      "\n",
      "    accuracy                           0.60      3995\n",
      "   macro avg       0.62      0.60      0.59      3995\n",
      "weighted avg       0.62      0.60      0.59      3995\n",
      "\n",
      "\n",
      "Classification Report (fold 5):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.41      0.50      1988\n",
      "           1       0.57      0.76      0.65      2007\n",
      "\n",
      "    accuracy                           0.59      3995\n",
      "   macro avg       0.60      0.59      0.57      3995\n",
      "weighted avg       0.60      0.59      0.58      3995\n",
      "\n",
      "\n",
      "Average Accuracy: 0.5917396745932415\n"
     ]
    }
   ],
   "source": [
    "RF_emoji_profile_count(fifa_df, fifa_df['Human_generated'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mSigRZGaivww"
   },
   "source": [
    "## Logistic Regression model for FIFA datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3kf_POK_iu4L",
    "outputId": "23f933dc-16ab-43f4-9f97-14266cda74bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (fold 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76      2032\n",
      "           1       0.74      0.78      0.76      1963\n",
      "\n",
      "    accuracy                           0.76      3995\n",
      "   macro avg       0.76      0.76      0.76      3995\n",
      "weighted avg       0.76      0.76      0.76      3995\n",
      "\n",
      "\n",
      "Classification Report (fold 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.76      0.77      1966\n",
      "           1       0.77      0.79      0.78      2029\n",
      "\n",
      "    accuracy                           0.77      3995\n",
      "   macro avg       0.77      0.77      0.77      3995\n",
      "weighted avg       0.77      0.77      0.77      3995\n",
      "\n",
      "\n",
      "Classification Report (fold 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.76      2001\n",
      "           1       0.76      0.80      0.78      1994\n",
      "\n",
      "    accuracy                           0.77      3995\n",
      "   macro avg       0.77      0.77      0.77      3995\n",
      "weighted avg       0.77      0.77      0.77      3995\n",
      "\n",
      "\n",
      "Classification Report (fold 4):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.73      0.76      1988\n",
      "           1       0.75      0.79      0.77      2007\n",
      "\n",
      "    accuracy                           0.76      3995\n",
      "   macro avg       0.76      0.76      0.76      3995\n",
      "weighted avg       0.76      0.76      0.76      3995\n",
      "\n",
      "\n",
      "Classification Report (fold 5):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.72      0.74      1988\n",
      "           1       0.74      0.78      0.76      2007\n",
      "\n",
      "    accuracy                           0.75      3995\n",
      "   macro avg       0.75      0.75      0.75      3995\n",
      "weighted avg       0.75      0.75      0.75      3995\n",
      "\n",
      "\n",
      "Average Accuracy: 0.7643053817271589\n",
      "Feature importance:\n",
      "seriously: -6.227630758109744\n",
      "amp: 4.583682013095917\n",
      "hey: -4.559290259024473\n",
      "shoutout: -4.19184026676904\n",
      "just: -4.032833056509266\n",
      "will: 3.9878046993988043\n",
      "vibe: -3.8459808971899414\n",
      "out: -3.7250211609751527\n",
      "believe: -3.6610403585567166\n",
      "epic: -3.636673851162227\n"
     ]
    }
   ],
   "source": [
    "LR_clean_tweets(fifa_df['clean_tweet'], fifa_df['Human_generated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (fold 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.73      0.76      1988\n",
      "           1       0.75      0.81      0.78      2007\n",
      "\n",
      "    accuracy                           0.77      3995\n",
      "   macro avg       0.77      0.77      0.77      3995\n",
      "weighted avg       0.77      0.77      0.77      3995\n",
      "\n",
      "\n",
      "Classification Report (fold 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.76      0.77      1972\n",
      "           1       0.77      0.80      0.79      2023\n",
      "\n",
      "    accuracy                           0.78      3995\n",
      "   macro avg       0.78      0.78      0.78      3995\n",
      "weighted avg       0.78      0.78      0.78      3995\n",
      "\n",
      "\n",
      "Classification Report (fold 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76      2016\n",
      "           1       0.75      0.78      0.77      1979\n",
      "\n",
      "    accuracy                           0.76      3995\n",
      "   macro avg       0.76      0.76      0.76      3995\n",
      "weighted avg       0.76      0.76      0.76      3995\n",
      "\n",
      "\n",
      "Classification Report (fold 4):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.74      0.76      1962\n",
      "           1       0.76      0.79      0.77      2033\n",
      "\n",
      "    accuracy                           0.77      3995\n",
      "   macro avg       0.77      0.77      0.77      3995\n",
      "weighted avg       0.77      0.77      0.77      3995\n",
      "\n",
      "\n",
      "Classification Report (fold 5):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.72      0.76      2037\n",
      "           1       0.74      0.81      0.77      1958\n",
      "\n",
      "    accuracy                           0.76      3995\n",
      "   macro avg       0.77      0.77      0.76      3995\n",
      "weighted avg       0.77      0.76      0.76      3995\n",
      "\n",
      "\n",
      "Average Accuracy: 0.7686107634543179\n"
     ]
    }
   ],
   "source": [
    "LR_tweet_emoji_profile(fifa_df, fifa_df['Human_generated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XxeIMrExYXS-",
    "outputId": "31a5fc11-2c40-4dc1-82a8-a1c24821a1d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (fold 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.80      0.63      2032\n",
      "           1       0.55      0.26      0.36      1963\n",
      "\n",
      "    accuracy                           0.53      3995\n",
      "   macro avg       0.54      0.53      0.50      3995\n",
      "weighted avg       0.54      0.53      0.50      3995\n",
      "\n",
      "\n",
      "Classification Report (fold 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.85      0.64      1966\n",
      "           1       0.59      0.20      0.30      2029\n",
      "\n",
      "    accuracy                           0.52      3995\n",
      "   macro avg       0.55      0.53      0.47      3995\n",
      "weighted avg       0.55      0.52      0.47      3995\n",
      "\n",
      "\n",
      "Classification Report (fold 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.85      0.65      2001\n",
      "           1       0.61      0.24      0.34      1994\n",
      "\n",
      "    accuracy                           0.54      3995\n",
      "   macro avg       0.57      0.54      0.50      3995\n",
      "weighted avg       0.57      0.54      0.50      3995\n",
      "\n",
      "\n",
      "Classification Report (fold 4):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.84      0.65      1988\n",
      "           1       0.61      0.24      0.35      2007\n",
      "\n",
      "    accuracy                           0.54      3995\n",
      "   macro avg       0.57      0.54      0.50      3995\n",
      "weighted avg       0.57      0.54      0.50      3995\n",
      "\n",
      "\n",
      "Classification Report (fold 5):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.84      0.65      1988\n",
      "           1       0.61      0.25      0.35      2007\n",
      "\n",
      "    accuracy                           0.54      3995\n",
      "   macro avg       0.57      0.55      0.50      3995\n",
      "weighted avg       0.57      0.54      0.50      3995\n",
      "\n",
      "\n",
      "Average Accuracy: 0.536720901126408\n"
     ]
    }
   ],
   "source": [
    "LR_emoji_profile_count(fifa_df, fifa_df['Human_generated'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gd4oc3HqujXY"
   },
   "source": [
    "## Decision tree model for FIFA datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vHzcnxZ0ruYt",
    "outputId": "6639cc8b-9603-481d-a1fb-6d592ef78134"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (fold 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.67      0.65      2032\n",
      "           1       0.64      0.61      0.63      1963\n",
      "\n",
      "    accuracy                           0.64      3995\n",
      "   macro avg       0.64      0.64      0.64      3995\n",
      "weighted avg       0.64      0.64      0.64      3995\n",
      "\n",
      "\n",
      "Classification Report (fold 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.65      0.64      1966\n",
      "           1       0.65      0.62      0.64      2029\n",
      "\n",
      "    accuracy                           0.64      3995\n",
      "   macro avg       0.64      0.64      0.64      3995\n",
      "weighted avg       0.64      0.64      0.64      3995\n",
      "\n",
      "\n",
      "Classification Report (fold 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.68      0.67      2001\n",
      "           1       0.67      0.63      0.65      1994\n",
      "\n",
      "    accuracy                           0.66      3995\n",
      "   macro avg       0.66      0.66      0.66      3995\n",
      "weighted avg       0.66      0.66      0.66      3995\n",
      "\n",
      "\n",
      "Classification Report (fold 4):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.66      0.65      1988\n",
      "           1       0.66      0.65      0.65      2007\n",
      "\n",
      "    accuracy                           0.65      3995\n",
      "   macro avg       0.65      0.65      0.65      3995\n",
      "weighted avg       0.65      0.65      0.65      3995\n",
      "\n",
      "\n",
      "Classification Report (fold 5):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.66      0.65      1988\n",
      "           1       0.66      0.64      0.65      2007\n",
      "\n",
      "    accuracy                           0.65      3995\n",
      "   macro avg       0.65      0.65      0.65      3995\n",
      "weighted avg       0.65      0.65      0.65      3995\n",
      "\n",
      "\n",
      "Average Accuracy: 0.648360450563204\n",
      "Feature importance:\n",
      "for: 0.03763980801219297\n",
      "let: 0.028028897226898063\n",
      "the: 0.027592390362724765\n",
      "qatar: 0.01975677020437099\n",
      "worldcup: 0.01819741984630779\n",
      "just: 0.017729567873590993\n",
      "be: 0.01763070976279043\n",
      "seriously: 0.016328503819020318\n",
      "can: 0.016198094592345245\n",
      "of: 0.013469562380365094\n"
     ]
    }
   ],
   "source": [
    "DT_clean_tweets(fifa_df['clean_tweet'], fifa_df['Human_generated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (fold 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.65      0.65      1988\n",
      "           1       0.65      0.64      0.65      2007\n",
      "\n",
      "    accuracy                           0.65      3995\n",
      "   macro avg       0.65      0.65      0.65      3995\n",
      "weighted avg       0.65      0.65      0.65      3995\n",
      "\n",
      "\n",
      "Classification Report (fold 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.67      0.65      1972\n",
      "           1       0.66      0.63      0.64      2023\n",
      "\n",
      "    accuracy                           0.65      3995\n",
      "   macro avg       0.65      0.65      0.65      3995\n",
      "weighted avg       0.65      0.65      0.65      3995\n",
      "\n",
      "\n",
      "Classification Report (fold 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.67      0.66      2016\n",
      "           1       0.66      0.64      0.65      1979\n",
      "\n",
      "    accuracy                           0.66      3995\n",
      "   macro avg       0.66      0.66      0.66      3995\n",
      "weighted avg       0.66      0.66      0.66      3995\n",
      "\n",
      "\n",
      "Classification Report (fold 4):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.65      0.65      1962\n",
      "           1       0.66      0.66      0.66      2033\n",
      "\n",
      "    accuracy                           0.65      3995\n",
      "   macro avg       0.65      0.65      0.65      3995\n",
      "weighted avg       0.65      0.65      0.65      3995\n",
      "\n",
      "\n",
      "Classification Report (fold 5):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.63      0.65      2037\n",
      "           1       0.64      0.67      0.66      1958\n",
      "\n",
      "    accuracy                           0.65      3995\n",
      "   macro avg       0.65      0.65      0.65      3995\n",
      "weighted avg       0.65      0.65      0.65      3995\n",
      "\n",
      "\n",
      "Average Accuracy: 0.6514643304130163\n"
     ]
    }
   ],
   "source": [
    "DT_tweet_emoji_profile(fifa_df, fifa_df['Human_generated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vWU5DyaYYpqF",
    "outputId": "5cf8184a-6273-4ba5-dfaa-0613d5882cdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (fold 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.40      0.50      2032\n",
      "           1       0.56      0.79      0.66      1963\n",
      "\n",
      "    accuracy                           0.59      3995\n",
      "   macro avg       0.61      0.60      0.58      3995\n",
      "weighted avg       0.61      0.59      0.58      3995\n",
      "\n",
      "\n",
      "Classification Report (fold 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.42      0.50      1966\n",
      "           1       0.57      0.74      0.64      2029\n",
      "\n",
      "    accuracy                           0.58      3995\n",
      "   macro avg       0.59      0.58      0.57      3995\n",
      "weighted avg       0.59      0.58      0.57      3995\n",
      "\n",
      "\n",
      "Classification Report (fold 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.43      0.52      2001\n",
      "           1       0.57      0.75      0.65      1994\n",
      "\n",
      "    accuracy                           0.59      3995\n",
      "   macro avg       0.60      0.59      0.58      3995\n",
      "weighted avg       0.60      0.59      0.58      3995\n",
      "\n",
      "\n",
      "Classification Report (fold 4):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.43      0.52      1988\n",
      "           1       0.58      0.77      0.66      2007\n",
      "\n",
      "    accuracy                           0.60      3995\n",
      "   macro avg       0.62      0.60      0.59      3995\n",
      "weighted avg       0.62      0.60      0.59      3995\n",
      "\n",
      "\n",
      "Classification Report (fold 5):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.41      0.50      1988\n",
      "           1       0.57      0.76      0.65      2007\n",
      "\n",
      "    accuracy                           0.59      3995\n",
      "   macro avg       0.60      0.59      0.57      3995\n",
      "weighted avg       0.60      0.59      0.57      3995\n",
      "\n",
      "\n",
      "Average Accuracy: 0.5914392991239049\n"
     ]
    }
   ],
   "source": [
    "DT_emoji_profile_count(fifa_df, fifa_df['Human_generated'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V-7_LTyeuvn7"
   },
   "source": [
    "## SVM model for Game of Thrones datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cLVb3TFzopeB",
    "outputId": "c83d0b62-8aba-4ae1-f099-1d4f4ee2723c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (fold 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2063\n",
      "           1       1.00      1.00      1.00      1937\n",
      "\n",
      "    accuracy                           1.00      4000\n",
      "   macro avg       1.00      1.00      1.00      4000\n",
      "weighted avg       1.00      1.00      1.00      4000\n",
      "\n",
      "\n",
      "Classification Report (fold 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1938\n",
      "           1       1.00      1.00      1.00      2062\n",
      "\n",
      "    accuracy                           1.00      4000\n",
      "   macro avg       1.00      1.00      1.00      4000\n",
      "weighted avg       1.00      1.00      1.00      4000\n",
      "\n",
      "\n",
      "Classification Report (fold 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2013\n",
      "           1       1.00      1.00      1.00      1987\n",
      "\n",
      "    accuracy                           1.00      4000\n",
      "   macro avg       1.00      1.00      1.00      4000\n",
      "weighted avg       1.00      1.00      1.00      4000\n",
      "\n",
      "\n",
      "Classification Report (fold 4):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1996\n",
      "           1       1.00      1.00      1.00      2004\n",
      "\n",
      "    accuracy                           1.00      4000\n",
      "   macro avg       1.00      1.00      1.00      4000\n",
      "weighted avg       1.00      1.00      1.00      4000\n",
      "\n",
      "\n",
      "Classification Report (fold 5):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1990\n",
      "           1       1.00      1.00      1.00      2010\n",
      "\n",
      "    accuracy                           1.00      4000\n",
      "   macro avg       1.00      1.00      1.00      4000\n",
      "weighted avg       1.00      1.00      1.00      4000\n",
      "\n",
      "\n",
      "Average Accuracy: 0.9995\n"
     ]
    }
   ],
   "source": [
    "SVM_clean_tweets(g_of_t_df['clean_tweet'], g_of_t_df['Human_generated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (fold 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.86      0.86      1981\n",
      "           1       0.86      0.87      0.87      2019\n",
      "\n",
      "    accuracy                           0.86      4000\n",
      "   macro avg       0.86      0.86      0.86      4000\n",
      "weighted avg       0.86      0.86      0.86      4000\n",
      "\n",
      "\n",
      "Classification Report (fold 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.88      1993\n",
      "           1       0.88      0.89      0.89      2007\n",
      "\n",
      "    accuracy                           0.88      4000\n",
      "   macro avg       0.88      0.88      0.88      4000\n",
      "weighted avg       0.88      0.88      0.88      4000\n",
      "\n",
      "\n",
      "Classification Report (fold 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88      2017\n",
      "           1       0.88      0.87      0.87      1983\n",
      "\n",
      "    accuracy                           0.88      4000\n",
      "   macro avg       0.88      0.88      0.88      4000\n",
      "weighted avg       0.88      0.88      0.88      4000\n",
      "\n",
      "\n",
      "Classification Report (fold 4):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.88      1965\n",
      "           1       0.87      0.89      0.88      2035\n",
      "\n",
      "    accuracy                           0.88      4000\n",
      "   macro avg       0.88      0.88      0.88      4000\n",
      "weighted avg       0.88      0.88      0.88      4000\n",
      "\n",
      "\n",
      "Classification Report (fold 5):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.88      2044\n",
      "           1       0.86      0.89      0.88      1956\n",
      "\n",
      "    accuracy                           0.88      4000\n",
      "   macro avg       0.88      0.88      0.88      4000\n",
      "weighted avg       0.88      0.88      0.88      4000\n",
      "\n",
      "\n",
      "Average Accuracy: 0.8761999999999999\n"
     ]
    }
   ],
   "source": [
    "SVM_tweet_emoji_profile(g_of_t_df, g_of_t_df['Human_generated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6D-rft8hZr7Q",
    "outputId": "21f9e67d-9b71-4f90-aeae-dab9125674f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (fold 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.87      0.65      2063\n",
      "           1       0.53      0.16      0.24      1937\n",
      "\n",
      "    accuracy                           0.52      4000\n",
      "   macro avg       0.52      0.51      0.45      4000\n",
      "weighted avg       0.52      0.52      0.45      4000\n",
      "\n",
      "\n",
      "Classification Report (fold 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.87      0.63      1938\n",
      "           1       0.56      0.16      0.25      2062\n",
      "\n",
      "    accuracy                           0.50      4000\n",
      "   macro avg       0.53      0.51      0.44      4000\n",
      "weighted avg       0.53      0.50      0.43      4000\n",
      "\n",
      "\n",
      "Classification Report (fold 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.87      0.65      2013\n",
      "           1       0.56      0.17      0.26      1987\n",
      "\n",
      "    accuracy                           0.52      4000\n",
      "   macro avg       0.54      0.52      0.45      4000\n",
      "weighted avg       0.54      0.52      0.45      4000\n",
      "\n",
      "\n",
      "Classification Report (fold 4):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.20      0.29      1996\n",
      "           1       0.50      0.81      0.62      2004\n",
      "\n",
      "    accuracy                           0.51      4000\n",
      "   macro avg       0.51      0.50      0.46      4000\n",
      "weighted avg       0.51      0.51      0.46      4000\n",
      "\n",
      "\n",
      "Classification Report (fold 5):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.87      0.64      1990\n",
      "           1       0.58      0.17      0.26      2010\n",
      "\n",
      "    accuracy                           0.52      4000\n",
      "   macro avg       0.54      0.52      0.45      4000\n",
      "weighted avg       0.54      0.52      0.45      4000\n",
      "\n",
      "\n",
      "Average Accuracy: 0.51445\n"
     ]
    }
   ],
   "source": [
    "SVM_emoji_profile_count(g_of_t_df, g_of_t_df['Human_generated'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qZs0_ft5h7gJ"
   },
   "source": [
    "## Random forest model for Game of Thrones datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "hEdqZy7eh4qD",
    "outputId": "72b20347-c7a2-4aaf-b75c-58e35289a47c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (fold 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2063\n",
      "           1       1.00      1.00      1.00      1937\n",
      "\n",
      "    accuracy                           1.00      4000\n",
      "   macro avg       1.00      1.00      1.00      4000\n",
      "weighted avg       1.00      1.00      1.00      4000\n",
      "\n",
      "\n",
      "Classification Report (fold 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1938\n",
      "           1       1.00      1.00      1.00      2062\n",
      "\n",
      "    accuracy                           1.00      4000\n",
      "   macro avg       1.00      1.00      1.00      4000\n",
      "weighted avg       1.00      1.00      1.00      4000\n",
      "\n",
      "\n",
      "Classification Report (fold 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2013\n",
      "           1       1.00      1.00      1.00      1987\n",
      "\n",
      "    accuracy                           1.00      4000\n",
      "   macro avg       1.00      1.00      1.00      4000\n",
      "weighted avg       1.00      1.00      1.00      4000\n",
      "\n",
      "\n",
      "Classification Report (fold 4):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1996\n",
      "           1       1.00      1.00      1.00      2004\n",
      "\n",
      "    accuracy                           1.00      4000\n",
      "   macro avg       1.00      1.00      1.00      4000\n",
      "weighted avg       1.00      1.00      1.00      4000\n",
      "\n",
      "\n",
      "Classification Report (fold 5):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1990\n",
      "           1       1.00      1.00      1.00      2010\n",
      "\n",
      "    accuracy                           1.00      4000\n",
      "   macro avg       1.00      1.00      1.00      4000\n",
      "weighted avg       1.00      1.00      1.00      4000\n",
      "\n",
      "\n",
      "Average Accuracy: 0.99975\n",
      "Feature importance:\n",
      "the: 0.10073616134668496\n",
      "of: 0.09328772093103\n",
      "be: 0.07422461221373618\n",
      "and: 0.06173410447293636\n",
      "to: 0.036946843707946514\n",
      "that: 0.027627636281693145\n",
      "for: 0.023671287077471945\n",
      "it: 0.02090752527426635\n",
      "this: 0.018685582079427398\n",
      "game: 0.01863019557738059\n"
     ]
    }
   ],
   "source": [
    "RF_clean_tweets(g_of_t_df['clean_tweet'], g_of_t_df['Human_generated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (fold 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1981\n",
      "           1       1.00      1.00      1.00      2019\n",
      "\n",
      "    accuracy                           1.00      4000\n",
      "   macro avg       1.00      1.00      1.00      4000\n",
      "weighted avg       1.00      1.00      1.00      4000\n",
      "\n",
      "\n",
      "Classification Report (fold 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1993\n",
      "           1       1.00      1.00      1.00      2007\n",
      "\n",
      "    accuracy                           1.00      4000\n",
      "   macro avg       1.00      1.00      1.00      4000\n",
      "weighted avg       1.00      1.00      1.00      4000\n",
      "\n",
      "\n",
      "Classification Report (fold 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2017\n",
      "           1       1.00      1.00      1.00      1983\n",
      "\n",
      "    accuracy                           1.00      4000\n",
      "   macro avg       1.00      1.00      1.00      4000\n",
      "weighted avg       1.00      1.00      1.00      4000\n",
      "\n",
      "\n",
      "Classification Report (fold 4):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1965\n",
      "           1       1.00      1.00      1.00      2035\n",
      "\n",
      "    accuracy                           1.00      4000\n",
      "   macro avg       1.00      1.00      1.00      4000\n",
      "weighted avg       1.00      1.00      1.00      4000\n",
      "\n",
      "\n",
      "Classification Report (fold 5):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2044\n",
      "           1       1.00      1.00      1.00      1956\n",
      "\n",
      "    accuracy                           1.00      4000\n",
      "   macro avg       1.00      1.00      1.00      4000\n",
      "weighted avg       1.00      1.00      1.00      4000\n",
      "\n",
      "\n",
      "Average Accuracy: 0.9998000000000001\n"
     ]
    }
   ],
   "source": [
    "RF_tweet_emoji_profile(g_of_t_df, g_of_t_df['Human_generated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "HDxWoV1MZ2wL",
    "outputId": "b3e660d4-692b-4168-8a7c-4d0d9750e38e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (fold 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.13      0.22      2063\n",
      "           1       0.51      0.98      0.67      1937\n",
      "\n",
      "    accuracy                           0.54      4000\n",
      "   macro avg       0.69      0.55      0.45      4000\n",
      "weighted avg       0.69      0.54      0.44      4000\n",
      "\n",
      "\n",
      "Classification Report (fold 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.84      0.63      1938\n",
      "           1       0.61      0.23      0.33      2062\n",
      "\n",
      "    accuracy                           0.53      4000\n",
      "   macro avg       0.56      0.53      0.48      4000\n",
      "weighted avg       0.56      0.53      0.48      4000\n",
      "\n",
      "\n",
      "Classification Report (fold 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.12      0.21      2013\n",
      "           1       0.52      0.98      0.68      1987\n",
      "\n",
      "    accuracy                           0.54      4000\n",
      "   macro avg       0.68      0.55      0.44      4000\n",
      "weighted avg       0.68      0.54      0.44      4000\n",
      "\n",
      "\n",
      "Classification Report (fold 4):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.11      0.19      1996\n",
      "           1       0.52      0.98      0.68      2004\n",
      "\n",
      "    accuracy                           0.55      4000\n",
      "   macro avg       0.68      0.54      0.44      4000\n",
      "weighted avg       0.68      0.55      0.44      4000\n",
      "\n",
      "\n",
      "Classification Report (fold 5):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.11      0.19      1990\n",
      "           1       0.53      0.98      0.68      2010\n",
      "\n",
      "    accuracy                           0.55      4000\n",
      "   macro avg       0.69      0.54      0.44      4000\n",
      "weighted avg       0.68      0.55      0.44      4000\n",
      "\n",
      "\n",
      "Average Accuracy: 0.5399499999999999\n"
     ]
    }
   ],
   "source": [
    "RF_emoji_profile_count(g_of_t_df, g_of_t_df['Human_generated'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q74VSHZ-i-MC"
   },
   "source": [
    "## Logistic Regression model for Game of Thrones datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "EBnF1Rm8i9fX",
    "outputId": "d1a15807-69f5-401d-a082-9ec5e89957ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (fold 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2063\n",
      "           1       1.00      1.00      1.00      1937\n",
      "\n",
      "    accuracy                           1.00      4000\n",
      "   macro avg       1.00      1.00      1.00      4000\n",
      "weighted avg       1.00      1.00      1.00      4000\n",
      "\n",
      "\n",
      "Classification Report (fold 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1938\n",
      "           1       1.00      1.00      1.00      2062\n",
      "\n",
      "    accuracy                           1.00      4000\n",
      "   macro avg       1.00      1.00      1.00      4000\n",
      "weighted avg       1.00      1.00      1.00      4000\n",
      "\n",
      "\n",
      "Classification Report (fold 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2013\n",
      "           1       1.00      0.99      1.00      1987\n",
      "\n",
      "    accuracy                           1.00      4000\n",
      "   macro avg       1.00      1.00      1.00      4000\n",
      "weighted avg       1.00      1.00      1.00      4000\n",
      "\n",
      "\n",
      "Classification Report (fold 4):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      1996\n",
      "           1       1.00      0.99      1.00      2004\n",
      "\n",
      "    accuracy                           1.00      4000\n",
      "   macro avg       1.00      1.00      1.00      4000\n",
      "weighted avg       1.00      1.00      1.00      4000\n",
      "\n",
      "\n",
      "Classification Report (fold 5):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      1990\n",
      "           1       1.00      0.99      1.00      2010\n",
      "\n",
      "    accuracy                           1.00      4000\n",
      "   macro avg       1.00      1.00      1.00      4000\n",
      "weighted avg       1.00      1.00      1.00      4000\n",
      "\n",
      "\n",
      "Average Accuracy: 0.99755\n",
      "Feature importance:\n",
      "of: 14.907694422240338\n",
      "the: 10.945842124078096\n",
      "be: 8.983285104689017\n",
      "to: 7.420395212171374\n",
      "and: 7.400602801021912\n",
      "in: 5.6549638252656935\n",
      "for: 5.307906731206569\n",
      "on: 4.796903649611825\n",
      "you: 4.544878155130731\n",
      "it: 4.504944181834101\n"
     ]
    }
   ],
   "source": [
    "LR_clean_tweets(g_of_t_df['clean_tweet'], g_of_t_df['Human_generated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (fold 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      1981\n",
      "           1       1.00      0.99      1.00      2019\n",
      "\n",
      "    accuracy                           1.00      4000\n",
      "   macro avg       1.00      1.00      1.00      4000\n",
      "weighted avg       1.00      1.00      1.00      4000\n",
      "\n",
      "\n",
      "Classification Report (fold 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      1993\n",
      "           1       1.00      0.99      1.00      2007\n",
      "\n",
      "    accuracy                           1.00      4000\n",
      "   macro avg       1.00      1.00      1.00      4000\n",
      "weighted avg       1.00      1.00      1.00      4000\n",
      "\n",
      "\n",
      "Classification Report (fold 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2017\n",
      "           1       1.00      0.99      1.00      1983\n",
      "\n",
      "    accuracy                           1.00      4000\n",
      "   macro avg       1.00      1.00      1.00      4000\n",
      "weighted avg       1.00      1.00      1.00      4000\n",
      "\n",
      "\n",
      "Classification Report (fold 4):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      1965\n",
      "           1       1.00      0.99      1.00      2035\n",
      "\n",
      "    accuracy                           1.00      4000\n",
      "   macro avg       1.00      1.00      1.00      4000\n",
      "weighted avg       1.00      1.00      1.00      4000\n",
      "\n",
      "\n",
      "Classification Report (fold 5):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2044\n",
      "           1       1.00      1.00      1.00      1956\n",
      "\n",
      "    accuracy                           1.00      4000\n",
      "   macro avg       1.00      1.00      1.00      4000\n",
      "weighted avg       1.00      1.00      1.00      4000\n",
      "\n",
      "\n",
      "Average Accuracy: 0.99655\n"
     ]
    }
   ],
   "source": [
    "LR_tweet_emoji_profile(g_of_t_df, g_of_t_df['Human_generated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "7nyoYONdZ_4M",
    "outputId": "adfb3576-bb89-4147-9af1-96bcd15ec6a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (fold 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.13      0.22      2063\n",
      "           1       0.51      0.98      0.67      1937\n",
      "\n",
      "    accuracy                           0.54      4000\n",
      "   macro avg       0.69      0.55      0.45      4000\n",
      "weighted avg       0.69      0.54      0.44      4000\n",
      "\n",
      "\n",
      "Classification Report (fold 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.84      0.63      1938\n",
      "           1       0.60      0.22      0.32      2062\n",
      "\n",
      "    accuracy                           0.52      4000\n",
      "   macro avg       0.55      0.53      0.48      4000\n",
      "weighted avg       0.55      0.52      0.47      4000\n",
      "\n",
      "\n",
      "Classification Report (fold 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.85      0.65      2013\n",
      "           1       0.60      0.23      0.33      1987\n",
      "\n",
      "    accuracy                           0.54      4000\n",
      "   macro avg       0.56      0.54      0.49      4000\n",
      "weighted avg       0.56      0.54      0.49      4000\n",
      "\n",
      "\n",
      "Classification Report (fold 4):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.11      0.19      1996\n",
      "           1       0.52      0.98      0.68      2004\n",
      "\n",
      "    accuracy                           0.54      4000\n",
      "   macro avg       0.67      0.54      0.44      4000\n",
      "weighted avg       0.67      0.54      0.44      4000\n",
      "\n",
      "\n",
      "Classification Report (fold 5):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.84      0.65      1990\n",
      "           1       0.61      0.24      0.35      2010\n",
      "\n",
      "    accuracy                           0.54      4000\n",
      "   macro avg       0.57      0.54      0.50      4000\n",
      "weighted avg       0.57      0.54      0.50      4000\n",
      "\n",
      "\n",
      "Average Accuracy: 0.53775\n"
     ]
    }
   ],
   "source": [
    "LR_emoji_profile_count(g_of_t_df, g_of_t_df['Human_generated'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZLe2lE6Tu49c"
   },
   "source": [
    "## Decision Tree model for Game of Thrones datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nTSeBXYCrzM8",
    "outputId": "5e3d571b-ca57-455e-c547-f333a3fa6971"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (fold 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2063\n",
      "           1       1.00      1.00      1.00      1937\n",
      "\n",
      "    accuracy                           1.00      4000\n",
      "   macro avg       1.00      1.00      1.00      4000\n",
      "weighted avg       1.00      1.00      1.00      4000\n",
      "\n",
      "\n",
      "Classification Report (fold 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1938\n",
      "           1       1.00      1.00      1.00      2062\n",
      "\n",
      "    accuracy                           1.00      4000\n",
      "   macro avg       1.00      1.00      1.00      4000\n",
      "weighted avg       1.00      1.00      1.00      4000\n",
      "\n",
      "\n",
      "Classification Report (fold 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2013\n",
      "           1       1.00      1.00      1.00      1987\n",
      "\n",
      "    accuracy                           1.00      4000\n",
      "   macro avg       1.00      1.00      1.00      4000\n",
      "weighted avg       1.00      1.00      1.00      4000\n",
      "\n",
      "\n",
      "Classification Report (fold 4):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1996\n",
      "           1       1.00      1.00      1.00      2004\n",
      "\n",
      "    accuracy                           1.00      4000\n",
      "   macro avg       1.00      1.00      1.00      4000\n",
      "weighted avg       1.00      1.00      1.00      4000\n",
      "\n",
      "\n",
      "Classification Report (fold 5):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1990\n",
      "           1       1.00      1.00      1.00      2010\n",
      "\n",
      "    accuracy                           1.00      4000\n",
      "   macro avg       1.00      1.00      1.00      4000\n",
      "weighted avg       1.00      1.00      1.00      4000\n",
      "\n",
      "\n",
      "Average Accuracy: 0.9998000000000001\n",
      "Feature importance:\n",
      "of: 0.9581434989556528\n",
      "the: 0.035129166904668135\n",
      "be: 0.006227458171403708\n",
      "that: 0.000499875968275378\n",
      "00: 0.0\n",
      "000140: 0.0\n",
      "001: 0.0\n",
      "002: 0.0\n",
      "004141: 0.0\n",
      "01: 0.0\n"
     ]
    }
   ],
   "source": [
    "DT_clean_tweets(g_of_t_df['clean_tweet'], g_of_t_df['Human_generated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (fold 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1981\n",
      "           1       1.00      1.00      1.00      2019\n",
      "\n",
      "    accuracy                           1.00      4000\n",
      "   macro avg       1.00      1.00      1.00      4000\n",
      "weighted avg       1.00      1.00      1.00      4000\n",
      "\n",
      "\n",
      "Classification Report (fold 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1993\n",
      "           1       1.00      1.00      1.00      2007\n",
      "\n",
      "    accuracy                           1.00      4000\n",
      "   macro avg       1.00      1.00      1.00      4000\n",
      "weighted avg       1.00      1.00      1.00      4000\n",
      "\n",
      "\n",
      "Classification Report (fold 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2017\n",
      "           1       1.00      1.00      1.00      1983\n",
      "\n",
      "    accuracy                           1.00      4000\n",
      "   macro avg       1.00      1.00      1.00      4000\n",
      "weighted avg       1.00      1.00      1.00      4000\n",
      "\n",
      "\n",
      "Classification Report (fold 4):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1965\n",
      "           1       1.00      1.00      1.00      2035\n",
      "\n",
      "    accuracy                           1.00      4000\n",
      "   macro avg       1.00      1.00      1.00      4000\n",
      "weighted avg       1.00      1.00      1.00      4000\n",
      "\n",
      "\n",
      "Classification Report (fold 5):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2044\n",
      "           1       1.00      1.00      1.00      1956\n",
      "\n",
      "    accuracy                           1.00      4000\n",
      "   macro avg       1.00      1.00      1.00      4000\n",
      "weighted avg       1.00      1.00      1.00      4000\n",
      "\n",
      "\n",
      "Average Accuracy: 0.9998000000000001\n"
     ]
    }
   ],
   "source": [
    "DT_tweet_emoji_profile(g_of_t_df, g_of_t_df['Human_generated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JGvITPSqaIZe",
    "outputId": "64be0bdd-7efe-41d3-f685-d90178a3a039"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (fold 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.13      0.22      2063\n",
      "           1       0.51      0.98      0.67      1937\n",
      "\n",
      "    accuracy                           0.54      4000\n",
      "   macro avg       0.69      0.55      0.45      4000\n",
      "weighted avg       0.69      0.54      0.44      4000\n",
      "\n",
      "\n",
      "Classification Report (fold 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.84      0.63      1938\n",
      "           1       0.61      0.23      0.33      2062\n",
      "\n",
      "    accuracy                           0.53      4000\n",
      "   macro avg       0.56      0.53      0.48      4000\n",
      "weighted avg       0.56      0.53      0.48      4000\n",
      "\n",
      "\n",
      "Classification Report (fold 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.12      0.21      2013\n",
      "           1       0.52      0.98      0.68      1987\n",
      "\n",
      "    accuracy                           0.54      4000\n",
      "   macro avg       0.68      0.55      0.44      4000\n",
      "weighted avg       0.68      0.54      0.44      4000\n",
      "\n",
      "\n",
      "Classification Report (fold 4):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.11      0.19      1996\n",
      "           1       0.52      0.98      0.68      2004\n",
      "\n",
      "    accuracy                           0.55      4000\n",
      "   macro avg       0.68      0.54      0.44      4000\n",
      "weighted avg       0.68      0.55      0.44      4000\n",
      "\n",
      "\n",
      "Classification Report (fold 5):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.11      0.19      1990\n",
      "           1       0.53      0.98      0.68      2010\n",
      "\n",
      "    accuracy                           0.55      4000\n",
      "   macro avg       0.68      0.54      0.44      4000\n",
      "weighted avg       0.68      0.55      0.44      4000\n",
      "\n",
      "\n",
      "Average Accuracy: 0.5399\n"
     ]
    }
   ],
   "source": [
    "DT_emoji_profile_count(g_of_t_df, g_of_t_df['Human_generated'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-ddjdoxu_Cs"
   },
   "source": [
    "## SVM model for election dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g1pcYU9Vp3f7",
    "outputId": "1fbb7674-fbfd-44d1-a1db-9abfd745f9d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (fold 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.65      0.71      2052\n",
      "         1.0       0.68      0.80      0.74      1928\n",
      "\n",
      "    accuracy                           0.72      3980\n",
      "   macro avg       0.73      0.72      0.72      3980\n",
      "weighted avg       0.73      0.72      0.72      3980\n",
      "\n",
      "\n",
      "Classification Report (fold 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.62      0.67      1912\n",
      "         1.0       0.69      0.79      0.74      2067\n",
      "\n",
      "    accuracy                           0.71      3979\n",
      "   macro avg       0.71      0.70      0.70      3979\n",
      "weighted avg       0.71      0.71      0.71      3979\n",
      "\n",
      "\n",
      "Classification Report (fold 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.66      0.70      1991\n",
      "         1.0       0.69      0.77      0.73      1988\n",
      "\n",
      "    accuracy                           0.72      3979\n",
      "   macro avg       0.72      0.72      0.72      3979\n",
      "weighted avg       0.72      0.72      0.72      3979\n",
      "\n",
      "\n",
      "Classification Report (fold 4):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.64      0.69      1976\n",
      "         1.0       0.69      0.78      0.73      2003\n",
      "\n",
      "    accuracy                           0.71      3979\n",
      "   macro avg       0.72      0.71      0.71      3979\n",
      "weighted avg       0.72      0.71      0.71      3979\n",
      "\n",
      "\n",
      "Classification Report (fold 5):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.65      0.69      1965\n",
      "         1.0       0.70      0.79      0.74      2014\n",
      "\n",
      "    accuracy                           0.72      3979\n",
      "   macro avg       0.72      0.72      0.72      3979\n",
      "weighted avg       0.72      0.72      0.72      3979\n",
      "\n",
      "\n",
      "Average Accuracy: 0.7156711681049126\n"
     ]
    }
   ],
   "source": [
    "SVM_clean_tweets(election_df['clean_tweet'], election_df['Human_generated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (fold 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.53      0.57      1958\n",
      "         1.0       0.60      0.68      0.63      2022\n",
      "\n",
      "    accuracy                           0.60      3980\n",
      "   macro avg       0.60      0.60      0.60      3980\n",
      "weighted avg       0.60      0.60      0.60      3980\n",
      "\n",
      "\n",
      "Classification Report (fold 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.54      0.56      1964\n",
      "         1.0       0.58      0.62      0.60      2015\n",
      "\n",
      "    accuracy                           0.58      3979\n",
      "   macro avg       0.58      0.58      0.58      3979\n",
      "weighted avg       0.58      0.58      0.58      3979\n",
      "\n",
      "\n",
      "Classification Report (fold 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.52      0.54      2003\n",
      "         1.0       0.56      0.61      0.58      1976\n",
      "\n",
      "    accuracy                           0.56      3979\n",
      "   macro avg       0.56      0.56      0.56      3979\n",
      "weighted avg       0.56      0.56      0.56      3979\n",
      "\n",
      "\n",
      "Classification Report (fold 4):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.54      0.56      1944\n",
      "         1.0       0.59      0.62      0.60      2035\n",
      "\n",
      "    accuracy                           0.58      3979\n",
      "   macro avg       0.58      0.58      0.58      3979\n",
      "weighted avg       0.58      0.58      0.58      3979\n",
      "\n",
      "\n",
      "Classification Report (fold 5):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.54      0.57      2027\n",
      "         1.0       0.57      0.63      0.60      1952\n",
      "\n",
      "    accuracy                           0.58      3979\n",
      "   macro avg       0.58      0.58      0.58      3979\n",
      "weighted avg       0.58      0.58      0.58      3979\n",
      "\n",
      "\n",
      "Average Accuracy: 0.5824778832589689\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(SVC(kernel='sigmoid'), 0.5824778832589689)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM_tweet_emoji_profile(election_df, election_df['Human_generated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wQ-MWUmLaRjU",
    "outputId": "fed552ad-1363-4fa8-b0ba-718591f39c2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (fold 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.63      0.56      2052\n",
      "         1.0       0.45      0.32      0.38      1928\n",
      "\n",
      "    accuracy                           0.48      3980\n",
      "   macro avg       0.48      0.48      0.47      3980\n",
      "weighted avg       0.48      0.48      0.47      3980\n",
      "\n",
      "\n",
      "Classification Report (fold 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.47      0.65      0.55      1912\n",
      "         1.0       0.50      0.32      0.39      2067\n",
      "\n",
      "    accuracy                           0.48      3979\n",
      "   macro avg       0.48      0.49      0.47      3979\n",
      "weighted avg       0.48      0.48      0.46      3979\n",
      "\n",
      "\n",
      "Classification Report (fold 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.64      0.54      1991\n",
      "         1.0       0.45      0.30      0.36      1988\n",
      "\n",
      "    accuracy                           0.47      3979\n",
      "   macro avg       0.46      0.47      0.45      3979\n",
      "weighted avg       0.46      0.47      0.45      3979\n",
      "\n",
      "\n",
      "Classification Report (fold 4):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.63      0.54      1976\n",
      "         1.0       0.47      0.32      0.38      2003\n",
      "\n",
      "    accuracy                           0.47      3979\n",
      "   macro avg       0.47      0.47      0.46      3979\n",
      "weighted avg       0.47      0.47      0.46      3979\n",
      "\n",
      "\n",
      "Classification Report (fold 5):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.66      0.56      1965\n",
      "         1.0       0.49      0.32      0.39      2014\n",
      "\n",
      "    accuracy                           0.49      3979\n",
      "   macro avg       0.49      0.49      0.48      3979\n",
      "weighted avg       0.49      0.49      0.47      3979\n",
      "\n",
      "\n",
      "Average Accuracy: 0.47833709891503257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(SVC(kernel='sigmoid'), 0.47833709891503257)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM_emoji_profile_count(election_df, election_df['Human_generated'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_3pgTU73iO1u"
   },
   "source": [
    "## Random forest model for election datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zx6zZsfZiSHG",
    "outputId": "029e3ded-597a-468a-9e37-c4196692b761"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (fold 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.67      0.67      2052\n",
      "         1.0       0.65      0.67      0.66      1928\n",
      "\n",
      "    accuracy                           0.67      3980\n",
      "   macro avg       0.67      0.67      0.67      3980\n",
      "weighted avg       0.67      0.67      0.67      3980\n",
      "\n",
      "\n",
      "Classification Report (fold 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.63      0.66      0.65      1912\n",
      "         1.0       0.67      0.64      0.65      2067\n",
      "\n",
      "    accuracy                           0.65      3979\n",
      "   macro avg       0.65      0.65      0.65      3979\n",
      "weighted avg       0.65      0.65      0.65      3979\n",
      "\n",
      "\n",
      "Classification Report (fold 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.69      0.67      1991\n",
      "         1.0       0.67      0.64      0.66      1988\n",
      "\n",
      "    accuracy                           0.66      3979\n",
      "   macro avg       0.66      0.66      0.66      3979\n",
      "weighted avg       0.66      0.66      0.66      3979\n",
      "\n",
      "\n",
      "Classification Report (fold 4):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.70      0.68      1976\n",
      "         1.0       0.68      0.63      0.66      2003\n",
      "\n",
      "    accuracy                           0.67      3979\n",
      "   macro avg       0.67      0.67      0.67      3979\n",
      "weighted avg       0.67      0.67      0.67      3979\n",
      "\n",
      "\n",
      "Classification Report (fold 5):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.71      0.68      1965\n",
      "         1.0       0.69      0.64      0.66      2014\n",
      "\n",
      "    accuracy                           0.67      3979\n",
      "   macro avg       0.67      0.67      0.67      3979\n",
      "weighted avg       0.67      0.67      0.67      3979\n",
      "\n",
      "\n",
      "Average Accuracy: 0.6641031495754722\n",
      "Feature importance:\n",
      "the: 0.01147765412581552\n",
      "just: 0.011069118146214954\n",
      "be: 0.010204241113764901\n",
      "joe: 0.010120594169585847\n",
      "hey: 0.00926865933911472\n",
      "to: 0.008723320752009281\n",
      "all: 0.008231742169268134\n",
      "out: 0.008160548764168534\n",
      "amp: 0.0074977314434621165\n",
      "let: 0.007299333196758676\n"
     ]
    }
   ],
   "source": [
    "RF_clean_tweets(election_df['clean_tweet'], election_df['Human_generated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (fold 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.68      0.67      1958\n",
      "         1.0       0.68      0.66      0.67      2022\n",
      "\n",
      "    accuracy                           0.67      3980\n",
      "   macro avg       0.67      0.67      0.67      3980\n",
      "weighted avg       0.67      0.67      0.67      3980\n",
      "\n",
      "\n",
      "Classification Report (fold 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.67      0.67      1964\n",
      "         1.0       0.68      0.67      0.68      2015\n",
      "\n",
      "    accuracy                           0.67      3979\n",
      "   macro avg       0.67      0.67      0.67      3979\n",
      "weighted avg       0.67      0.67      0.67      3979\n",
      "\n",
      "\n",
      "Classification Report (fold 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.67      0.68      2003\n",
      "         1.0       0.67      0.68      0.68      1976\n",
      "\n",
      "    accuracy                           0.68      3979\n",
      "   macro avg       0.68      0.68      0.68      3979\n",
      "weighted avg       0.68      0.68      0.68      3979\n",
      "\n",
      "\n",
      "Classification Report (fold 4):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.68      0.67      1944\n",
      "         1.0       0.69      0.67      0.68      2035\n",
      "\n",
      "    accuracy                           0.68      3979\n",
      "   macro avg       0.68      0.68      0.68      3979\n",
      "weighted avg       0.68      0.68      0.68      3979\n",
      "\n",
      "\n",
      "Classification Report (fold 5):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.68      0.67      2027\n",
      "         1.0       0.66      0.65      0.65      1952\n",
      "\n",
      "    accuracy                           0.66      3979\n",
      "   macro avg       0.66      0.66      0.66      3979\n",
      "weighted avg       0.66      0.66      0.66      3979\n",
      "\n",
      "\n",
      "Average Accuracy: 0.6719441894064442\n"
     ]
    }
   ],
   "source": [
    "RF_tweet_emoji_profile(election_df, election_df['Human_generated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tM10vwqIaZx1",
    "outputId": "c4c47ec3-5f6e-4b8e-a9b4-950c12369ebe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (fold 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.20      0.30      2052\n",
      "         1.0       0.51      0.89      0.65      1928\n",
      "\n",
      "    accuracy                           0.53      3980\n",
      "   macro avg       0.58      0.54      0.47      3980\n",
      "weighted avg       0.58      0.53      0.47      3980\n",
      "\n",
      "\n",
      "Classification Report (fold 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.21      0.31      1912\n",
      "         1.0       0.55      0.90      0.68      2067\n",
      "\n",
      "    accuracy                           0.57      3979\n",
      "   macro avg       0.60      0.55      0.50      3979\n",
      "weighted avg       0.60      0.57      0.51      3979\n",
      "\n",
      "\n",
      "Classification Report (fold 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.21      0.32      1991\n",
      "         1.0       0.53      0.91      0.67      1988\n",
      "\n",
      "    accuracy                           0.56      3979\n",
      "   macro avg       0.62      0.56      0.50      3979\n",
      "weighted avg       0.62      0.56      0.50      3979\n",
      "\n",
      "\n",
      "Classification Report (fold 4):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.20      0.31      1976\n",
      "         1.0       0.54      0.91      0.67      2003\n",
      "\n",
      "    accuracy                           0.56      3979\n",
      "   macro avg       0.61      0.55      0.49      3979\n",
      "weighted avg       0.61      0.56      0.49      3979\n",
      "\n",
      "\n",
      "Classification Report (fold 5):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.18      0.28      1965\n",
      "         1.0       0.53      0.90      0.67      2014\n",
      "\n",
      "    accuracy                           0.55      3979\n",
      "   macro avg       0.59      0.54      0.48      3979\n",
      "weighted avg       0.59      0.55      0.48      3979\n",
      "\n",
      "\n",
      "Average Accuracy: 0.5520718192621816\n"
     ]
    }
   ],
   "source": [
    "RF_emoji_profile_count(election_df, election_df['Human_generated'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xH6lQDqqjHh_"
   },
   "source": [
    "## Logistic Regression model for election datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NGB1tCnUjKD0",
    "outputId": "7c7e4581-579c-485e-cb27-a7eec09dfdc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (fold 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.66      0.71      2052\n",
      "         1.0       0.69      0.80      0.74      1928\n",
      "\n",
      "    accuracy                           0.73      3980\n",
      "   macro avg       0.73      0.73      0.73      3980\n",
      "weighted avg       0.73      0.73      0.73      3980\n",
      "\n",
      "\n",
      "Classification Report (fold 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.65      0.68      1912\n",
      "         1.0       0.70      0.78      0.74      2067\n",
      "\n",
      "    accuracy                           0.71      3979\n",
      "   macro avg       0.71      0.71      0.71      3979\n",
      "weighted avg       0.71      0.71      0.71      3979\n",
      "\n",
      "\n",
      "Classification Report (fold 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.67      0.70      1991\n",
      "         1.0       0.70      0.76      0.73      1988\n",
      "\n",
      "    accuracy                           0.72      3979\n",
      "   macro avg       0.72      0.72      0.71      3979\n",
      "weighted avg       0.72      0.72      0.71      3979\n",
      "\n",
      "\n",
      "Classification Report (fold 4):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.66      0.70      1976\n",
      "         1.0       0.70      0.78      0.74      2003\n",
      "\n",
      "    accuracy                           0.72      3979\n",
      "   macro avg       0.72      0.72      0.72      3979\n",
      "weighted avg       0.72      0.72      0.72      3979\n",
      "\n",
      "\n",
      "Classification Report (fold 5):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.68      0.71      1965\n",
      "         1.0       0.71      0.77      0.74      2014\n",
      "\n",
      "    accuracy                           0.73      3979\n",
      "   macro avg       0.73      0.73      0.73      3979\n",
      "weighted avg       0.73      0.73      0.73      3979\n",
      "\n",
      "\n",
      "Average Accuracy: 0.7207978192040878\n",
      "Feature importance:\n",
      "hey: -6.4678098202631915\n",
      "amp: 5.390306912215405\n",
      "seriously: -4.725096693894487\n",
      "check: -4.562431587987803\n",
      "let: -4.464245301734381\n",
      "just: -4.345632950617783\n",
      "yo: -4.1426874302745835\n",
      "mess: -3.762599165137398\n",
      "shoutout: -3.7385807061561227\n",
      "wild: -3.6573887439071995\n"
     ]
    }
   ],
   "source": [
    "LR_clean_tweets(election_df['clean_tweet'], election_df['Human_generated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (fold 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.68      0.71      1958\n",
      "         1.0       0.71      0.78      0.74      2022\n",
      "\n",
      "    accuracy                           0.73      3980\n",
      "   macro avg       0.73      0.73      0.73      3980\n",
      "weighted avg       0.73      0.73      0.73      3980\n",
      "\n",
      "\n",
      "Classification Report (fold 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.67      0.71      1964\n",
      "         1.0       0.71      0.79      0.75      2015\n",
      "\n",
      "    accuracy                           0.73      3979\n",
      "   macro avg       0.73      0.73      0.73      3979\n",
      "weighted avg       0.73      0.73      0.73      3979\n",
      "\n",
      "\n",
      "Classification Report (fold 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.65      0.69      2003\n",
      "         1.0       0.69      0.78      0.73      1976\n",
      "\n",
      "    accuracy                           0.71      3979\n",
      "   macro avg       0.72      0.71      0.71      3979\n",
      "weighted avg       0.72      0.71      0.71      3979\n",
      "\n",
      "\n",
      "Classification Report (fold 4):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.67      0.70      1944\n",
      "         1.0       0.71      0.78      0.74      2035\n",
      "\n",
      "    accuracy                           0.73      3979\n",
      "   macro avg       0.73      0.72      0.72      3979\n",
      "weighted avg       0.73      0.73      0.72      3979\n",
      "\n",
      "\n",
      "Classification Report (fold 5):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.66      0.71      2027\n",
      "         1.0       0.69      0.78      0.74      1952\n",
      "\n",
      "    accuracy                           0.72      3979\n",
      "   macro avg       0.73      0.72      0.72      3979\n",
      "weighted avg       0.73      0.72      0.72      3979\n",
      "\n",
      "\n",
      "Average Accuracy: 0.7237633126678884\n"
     ]
    }
   ],
   "source": [
    "LR_tweet_emoji_profile(election_df, election_df['Human_generated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CYONC_z1af5e",
    "outputId": "9cc5e53d-4720-40fe-efc3-d9477e71cdf8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (fold 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.68      0.60      2052\n",
      "         1.0       0.53      0.38      0.44      1928\n",
      "\n",
      "    accuracy                           0.54      3980\n",
      "   macro avg       0.53      0.53      0.52      3980\n",
      "weighted avg       0.53      0.54      0.52      3980\n",
      "\n",
      "\n",
      "Classification Report (fold 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.71      0.60      1912\n",
      "         1.0       0.59      0.38      0.46      2067\n",
      "\n",
      "    accuracy                           0.54      3979\n",
      "   macro avg       0.55      0.55      0.53      3979\n",
      "weighted avg       0.55      0.54      0.53      3979\n",
      "\n",
      "\n",
      "Classification Report (fold 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.70      0.60      1991\n",
      "         1.0       0.56      0.39      0.46      1988\n",
      "\n",
      "    accuracy                           0.54      3979\n",
      "   macro avg       0.55      0.54      0.53      3979\n",
      "weighted avg       0.55      0.54      0.53      3979\n",
      "\n",
      "\n",
      "Classification Report (fold 4):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.67      0.58      1976\n",
      "         1.0       0.54      0.38      0.45      2003\n",
      "\n",
      "    accuracy                           0.53      3979\n",
      "   macro avg       0.53      0.53      0.52      3979\n",
      "weighted avg       0.53      0.53      0.52      3979\n",
      "\n",
      "\n",
      "Classification Report (fold 5):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.70      0.60      1965\n",
      "         1.0       0.56      0.37      0.45      2014\n",
      "\n",
      "    accuracy                           0.54      3979\n",
      "   macro avg       0.54      0.54      0.52      3979\n",
      "weighted avg       0.54      0.54      0.52      3979\n",
      "\n",
      "\n",
      "Average Accuracy: 0.5357861056981312\n"
     ]
    }
   ],
   "source": [
    "LR_emoji_profile_count(election_df, election_df['Human_generated'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9FcotNMEvEhX"
   },
   "source": [
    "## Decision Tree model for election datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JLiLdVf5rMqc",
    "outputId": "75d2327d-f1f6-4726-9ef6-76132e4682bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (fold 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.59      0.60      2052\n",
      "         1.0       0.58      0.61      0.59      1928\n",
      "\n",
      "    accuracy                           0.60      3980\n",
      "   macro avg       0.60      0.60      0.60      3980\n",
      "weighted avg       0.60      0.60      0.60      3980\n",
      "\n",
      "\n",
      "Classification Report (fold 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.59      0.58      1912\n",
      "         1.0       0.61      0.60      0.60      2067\n",
      "\n",
      "    accuracy                           0.59      3979\n",
      "   macro avg       0.59      0.59      0.59      3979\n",
      "weighted avg       0.59      0.59      0.59      3979\n",
      "\n",
      "\n",
      "Classification Report (fold 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.61      0.60      1991\n",
      "         1.0       0.60      0.58      0.59      1988\n",
      "\n",
      "    accuracy                           0.60      3979\n",
      "   macro avg       0.60      0.60      0.60      3979\n",
      "weighted avg       0.60      0.60      0.60      3979\n",
      "\n",
      "\n",
      "Classification Report (fold 4):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.61      0.60      1976\n",
      "         1.0       0.60      0.58      0.59      2003\n",
      "\n",
      "    accuracy                           0.59      3979\n",
      "   macro avg       0.59      0.59      0.59      3979\n",
      "weighted avg       0.60      0.59      0.59      3979\n",
      "\n",
      "\n",
      "Classification Report (fold 5):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.62      0.61      1965\n",
      "         1.0       0.61      0.59      0.60      2014\n",
      "\n",
      "    accuracy                           0.60      3979\n",
      "   macro avg       0.60      0.60      0.60      3979\n",
      "weighted avg       0.60      0.60      0.60      3979\n",
      "\n",
      "\n",
      "Average Accuracy: 0.5973561575153981\n",
      "Feature importance:\n",
      "just: 0.032473498064309964\n",
      "hey: 0.022764205609567885\n",
      "out: 0.022583423569005816\n",
      "let: 0.020984163681643447\n",
      "the: 0.01967659575851899\n",
      "joe: 0.018414126054612026\n",
      "be: 0.018283867027631902\n",
      "amp: 0.017882764035798672\n",
      "like: 0.01755929699287401\n",
      "to: 0.01454837107142047\n"
     ]
    }
   ],
   "source": [
    "DT_clean_tweets(election_df['clean_tweet'], election_df['Human_generated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (fold 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.61      0.61      1958\n",
      "         1.0       0.62      0.61      0.61      2022\n",
      "\n",
      "    accuracy                           0.61      3980\n",
      "   macro avg       0.61      0.61      0.61      3980\n",
      "weighted avg       0.61      0.61      0.61      3980\n",
      "\n",
      "\n",
      "Classification Report (fold 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.60      0.60      1964\n",
      "         1.0       0.61      0.61      0.61      2015\n",
      "\n",
      "    accuracy                           0.60      3979\n",
      "   macro avg       0.60      0.60      0.60      3979\n",
      "weighted avg       0.60      0.60      0.60      3979\n",
      "\n",
      "\n",
      "Classification Report (fold 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.59      0.60      2003\n",
      "         1.0       0.60      0.62      0.61      1976\n",
      "\n",
      "    accuracy                           0.60      3979\n",
      "   macro avg       0.61      0.61      0.60      3979\n",
      "weighted avg       0.61      0.60      0.60      3979\n",
      "\n",
      "\n",
      "Classification Report (fold 4):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.61      0.61      1944\n",
      "         1.0       0.62      0.63      0.63      2035\n",
      "\n",
      "    accuracy                           0.62      3979\n",
      "   macro avg       0.62      0.62      0.62      3979\n",
      "weighted avg       0.62      0.62      0.62      3979\n",
      "\n",
      "\n",
      "Classification Report (fold 5):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.60      0.60      2027\n",
      "         1.0       0.59      0.59      0.59      1952\n",
      "\n",
      "    accuracy                           0.60      3979\n",
      "   macro avg       0.60      0.60      0.60      3979\n",
      "weighted avg       0.60      0.60      0.60      3979\n",
      "\n",
      "\n",
      "Average Accuracy: 0.6066544206329461\n"
     ]
    }
   ],
   "source": [
    "DT_tweet_emoji_profile(election_df, election_df['Human_generated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mAV05d6OakxY",
    "outputId": "0d7fb083-c7bb-45c4-92a6-0d2070f0fdf9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (fold 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.20      0.30      2052\n",
      "         1.0       0.51      0.88      0.65      1928\n",
      "\n",
      "    accuracy                           0.53      3980\n",
      "   macro avg       0.58      0.54      0.47      3980\n",
      "weighted avg       0.58      0.53      0.47      3980\n",
      "\n",
      "\n",
      "Classification Report (fold 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.21      0.31      1912\n",
      "         1.0       0.55      0.90      0.68      2067\n",
      "\n",
      "    accuracy                           0.57      3979\n",
      "   macro avg       0.60      0.55      0.50      3979\n",
      "weighted avg       0.60      0.57      0.51      3979\n",
      "\n",
      "\n",
      "Classification Report (fold 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.21      0.32      1991\n",
      "         1.0       0.53      0.91      0.67      1988\n",
      "\n",
      "    accuracy                           0.56      3979\n",
      "   macro avg       0.62      0.56      0.50      3979\n",
      "weighted avg       0.62      0.56      0.50      3979\n",
      "\n",
      "\n",
      "Classification Report (fold 4):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.20      0.31      1976\n",
      "         1.0       0.53      0.91      0.67      2003\n",
      "\n",
      "    accuracy                           0.56      3979\n",
      "   macro avg       0.61      0.55      0.49      3979\n",
      "weighted avg       0.61      0.56      0.49      3979\n",
      "\n",
      "\n",
      "Classification Report (fold 5):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.18      0.29      1965\n",
      "         1.0       0.53      0.90      0.67      2014\n",
      "\n",
      "    accuracy                           0.55      3979\n",
      "   macro avg       0.59      0.54      0.48      3979\n",
      "weighted avg       0.59      0.55      0.48      3979\n",
      "\n",
      "\n",
      "Average Accuracy: 0.5515692056664321\n"
     ]
    }
   ],
   "source": [
    "DT_emoji_profile_count(election_df, election_df['Human_generated'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zzz_UPeGDAjX"
   },
   "source": [
    "## SVM model for combined datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "kqnSZjQRDAz-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (fold 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.78      0.79      5988\n",
      "         1.0       0.78      0.82      0.80      5987\n",
      "\n",
      "    accuracy                           0.80     11975\n",
      "   macro avg       0.80      0.80      0.80     11975\n",
      "weighted avg       0.80      0.80      0.80     11975\n",
      "\n",
      "\n",
      "Classification Report (fold 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.77      0.79      6112\n",
      "         1.0       0.78      0.82      0.80      5862\n",
      "\n",
      "    accuracy                           0.80     11974\n",
      "   macro avg       0.80      0.80      0.80     11974\n",
      "weighted avg       0.80      0.80      0.80     11974\n",
      "\n",
      "\n",
      "Classification Report (fold 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.78      0.80      5937\n",
      "         1.0       0.79      0.82      0.81      6037\n",
      "\n",
      "    accuracy                           0.80     11974\n",
      "   macro avg       0.80      0.80      0.80     11974\n",
      "weighted avg       0.80      0.80      0.80     11974\n",
      "\n",
      "\n",
      "Classification Report (fold 4):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.78      0.79      5932\n",
      "         1.0       0.79      0.82      0.80      6042\n",
      "\n",
      "    accuracy                           0.80     11974\n",
      "   macro avg       0.80      0.80      0.80     11974\n",
      "weighted avg       0.80      0.80      0.80     11974\n",
      "\n",
      "\n",
      "Classification Report (fold 5):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.77      0.79      5902\n",
      "         1.0       0.79      0.82      0.80      6072\n",
      "\n",
      "    accuracy                           0.79     11974\n",
      "   macro avg       0.80      0.79      0.79     11974\n",
      "weighted avg       0.80      0.79      0.79     11974\n",
      "\n",
      "\n",
      "Average Accuracy: 0.7971472107450625\n"
     ]
    }
   ],
   "source": [
    "SVM_clean_tweets(all_df['clean_tweet'], all_df['Human_generated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (fold 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.64      0.65      5978\n",
      "         1.0       0.66      0.68      0.67      5997\n",
      "\n",
      "    accuracy                           0.66     11975\n",
      "   macro avg       0.66      0.66      0.66     11975\n",
      "weighted avg       0.66      0.66      0.66     11975\n",
      "\n",
      "\n",
      "Classification Report (fold 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.65      0.66      5989\n",
      "         1.0       0.66      0.68      0.67      5985\n",
      "\n",
      "    accuracy                           0.66     11974\n",
      "   macro avg       0.66      0.66      0.66     11974\n",
      "weighted avg       0.66      0.66      0.66     11974\n",
      "\n",
      "\n",
      "Classification Report (fold 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.65      0.66      6045\n",
      "         1.0       0.66      0.68      0.67      5929\n",
      "\n",
      "    accuracy                           0.67     11974\n",
      "   macro avg       0.67      0.67      0.67     11974\n",
      "weighted avg       0.67      0.67      0.67     11974\n",
      "\n",
      "\n",
      "Classification Report (fold 4):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.65      0.66      5922\n",
      "         1.0       0.67      0.69      0.68      6052\n",
      "\n",
      "    accuracy                           0.67     11974\n",
      "   macro avg       0.67      0.67      0.67     11974\n",
      "weighted avg       0.67      0.67      0.67     11974\n",
      "\n",
      "\n",
      "Classification Report (fold 5):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.64      0.65      5937\n",
      "         1.0       0.66      0.69      0.67      6037\n",
      "\n",
      "    accuracy                           0.66     11974\n",
      "   macro avg       0.66      0.66      0.66     11974\n",
      "weighted avg       0.66      0.66      0.66     11974\n",
      "\n",
      "\n",
      "Average Accuracy: 0.6653973156173798\n"
     ]
    }
   ],
   "source": [
    "SVM_tweet_emoji_profile(all_df, all_df['Human_generated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7VvcXsbFDmtB",
    "outputId": "42eb2803-28bd-45e6-fef6-3e97d60cebb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (fold 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.76      0.60      5988\n",
      "         1.0       0.49      0.23      0.32      5987\n",
      "\n",
      "    accuracy                           0.49     11975\n",
      "   macro avg       0.49      0.49      0.46     11975\n",
      "weighted avg       0.49      0.49      0.46     11975\n",
      "\n",
      "\n",
      "Classification Report (fold 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.76      0.61      6112\n",
      "         1.0       0.49      0.24      0.32      5862\n",
      "\n",
      "    accuracy                           0.51     11974\n",
      "   macro avg       0.50      0.50      0.47     11974\n",
      "weighted avg       0.50      0.51      0.47     11974\n",
      "\n",
      "\n",
      "Classification Report (fold 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.76      0.60      5937\n",
      "         1.0       0.51      0.24      0.33      6037\n",
      "\n",
      "    accuracy                           0.50     11974\n",
      "   macro avg       0.50      0.50      0.46     11974\n",
      "weighted avg       0.50      0.50      0.46     11974\n",
      "\n",
      "\n",
      "Classification Report (fold 4):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.76      0.60      5932\n",
      "         1.0       0.51      0.24      0.33      6042\n",
      "\n",
      "    accuracy                           0.50     11974\n",
      "   macro avg       0.50      0.50      0.47     11974\n",
      "weighted avg       0.50      0.50      0.46     11974\n",
      "\n",
      "\n",
      "Classification Report (fold 5):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.76      0.60      5902\n",
      "         1.0       0.50      0.24      0.32      6072\n",
      "\n",
      "    accuracy                           0.49     11974\n",
      "   macro avg       0.50      0.50      0.46     11974\n",
      "weighted avg       0.50      0.49      0.46     11974\n",
      "\n",
      "\n",
      "Average Accuracy: 0.4988225358143758\n"
     ]
    }
   ],
   "source": [
    "SVM_emoji_profile_count(all_df, all_df['Human_generated'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9W6-5TsJDmz0"
   },
   "source": [
    "## Random forest model for combined datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "FCNZJD4GDm66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (fold 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.78      0.79      5988\n",
      "         1.0       0.79      0.81      0.80      5987\n",
      "\n",
      "    accuracy                           0.79     11975\n",
      "   macro avg       0.79      0.79      0.79     11975\n",
      "weighted avg       0.79      0.79      0.79     11975\n",
      "\n",
      "\n",
      "Classification Report (fold 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.77      0.79      6112\n",
      "         1.0       0.77      0.81      0.79      5862\n",
      "\n",
      "    accuracy                           0.79     11974\n",
      "   macro avg       0.79      0.79      0.79     11974\n",
      "weighted avg       0.79      0.79      0.79     11974\n",
      "\n",
      "\n",
      "Classification Report (fold 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.79      0.79      5937\n",
      "         1.0       0.79      0.81      0.80      6037\n",
      "\n",
      "    accuracy                           0.80     11974\n",
      "   macro avg       0.80      0.80      0.80     11974\n",
      "weighted avg       0.80      0.80      0.80     11974\n",
      "\n",
      "\n",
      "Classification Report (fold 4):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.78      0.79      5932\n",
      "         1.0       0.79      0.81      0.80      6042\n",
      "\n",
      "    accuracy                           0.79     11974\n",
      "   macro avg       0.79      0.79      0.79     11974\n",
      "weighted avg       0.79      0.79      0.79     11974\n",
      "\n",
      "\n",
      "Classification Report (fold 5):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.77      0.78      5902\n",
      "         1.0       0.78      0.81      0.80      6072\n",
      "\n",
      "    accuracy                           0.79     11974\n",
      "   macro avg       0.79      0.79      0.79     11974\n",
      "weighted avg       0.79      0.79      0.79     11974\n",
      "\n",
      "\n",
      "Average Accuracy: 0.7926374758392661\n",
      "Feature importance:\n",
      "of: 0.031586500983834434\n",
      "game: 0.030421975306082066\n",
      "throne: 0.02515575868065659\n",
      "be: 0.01568187076864556\n",
      "the: 0.013694294172500834\n",
      "to: 0.010725219330680508\n",
      "have: 0.009114440974527823\n",
      "in: 0.00865307600455708\n",
      "and: 0.008651854641768842\n",
      "for: 0.007895912163554985\n"
     ]
    }
   ],
   "source": [
    "RF_clean_tweets(all_df['clean_tweet'], all_df['Human_generated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (fold 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.58      0.53      5978\n",
      "         1.0       0.49      0.41      0.44      5997\n",
      "\n",
      "    accuracy                           0.49     11975\n",
      "   macro avg       0.49      0.49      0.49     11975\n",
      "weighted avg       0.49      0.49      0.49     11975\n",
      "\n",
      "\n",
      "Classification Report (fold 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.59      0.54      5989\n",
      "         1.0       0.50      0.42      0.46      5985\n",
      "\n",
      "    accuracy                           0.50     11974\n",
      "   macro avg       0.50      0.50      0.50     11974\n",
      "weighted avg       0.50      0.50      0.50     11974\n",
      "\n",
      "\n",
      "Classification Report (fold 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.58      0.54      6045\n",
      "         1.0       0.49      0.42      0.46      5929\n",
      "\n",
      "    accuracy                           0.50     11974\n",
      "   macro avg       0.50      0.50      0.50     11974\n",
      "weighted avg       0.50      0.50      0.50     11974\n",
      "\n",
      "\n",
      "Classification Report (fold 4):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.59      0.54      5922\n",
      "         1.0       0.51      0.42      0.46      6052\n",
      "\n",
      "    accuracy                           0.50     11974\n",
      "   macro avg       0.50      0.50      0.50     11974\n",
      "weighted avg       0.50      0.50      0.50     11974\n",
      "\n",
      "\n",
      "Classification Report (fold 5):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.58      0.53      5937\n",
      "         1.0       0.49      0.40      0.44      6037\n",
      "\n",
      "    accuracy                           0.49     11974\n",
      "   macro avg       0.49      0.49      0.49     11974\n",
      "weighted avg       0.49      0.49      0.49     11974\n",
      "\n",
      "\n",
      "Average Accuracy: 0.4974696616503468\n"
     ]
    }
   ],
   "source": [
    "RF_tweet_emoji_profile(all_df, all_df['Human_generated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "0YGO3cfrFVmB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (fold 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.20      0.28      5988\n",
      "         1.0       0.50      0.80      0.62      5987\n",
      "\n",
      "    accuracy                           0.50     11975\n",
      "   macro avg       0.50      0.50      0.45     11975\n",
      "weighted avg       0.50      0.50      0.45     11975\n",
      "\n",
      "\n",
      "Classification Report (fold 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.10      0.16      6112\n",
      "         1.0       0.49      0.90      0.63      5862\n",
      "\n",
      "    accuracy                           0.49     11974\n",
      "   macro avg       0.50      0.50      0.40     11974\n",
      "weighted avg       0.50      0.49      0.39     11974\n",
      "\n",
      "\n",
      "Classification Report (fold 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.28      0.36      5937\n",
      "         1.0       0.50      0.71      0.59      6037\n",
      "\n",
      "    accuracy                           0.50     11974\n",
      "   macro avg       0.50      0.50      0.47     11974\n",
      "weighted avg       0.50      0.50      0.47     11974\n",
      "\n",
      "\n",
      "Classification Report (fold 4):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.31      0.38      5932\n",
      "         1.0       0.50      0.68      0.58      6042\n",
      "\n",
      "    accuracy                           0.50     11974\n",
      "   macro avg       0.50      0.50      0.48     11974\n",
      "weighted avg       0.50      0.50      0.48     11974\n",
      "\n",
      "\n",
      "Classification Report (fold 5):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.76      0.60      5902\n",
      "         1.0       0.50      0.23      0.31      6072\n",
      "\n",
      "    accuracy                           0.49     11974\n",
      "   macro avg       0.49      0.49      0.45     11974\n",
      "weighted avg       0.49      0.49      0.45     11974\n",
      "\n",
      "\n",
      "Average Accuracy: 0.4958660368167215\n"
     ]
    }
   ],
   "source": [
    "RF_emoji_profile_count(all_df, all_df['Human_generated'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nJT_PGJGDnBf"
   },
   "source": [
    "## Logistic Regression model for combined datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "wD_kXXB-DnHC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (fold 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.79      0.80      5988\n",
      "         1.0       0.80      0.82      0.81      5987\n",
      "\n",
      "    accuracy                           0.81     11975\n",
      "   macro avg       0.81      0.81      0.81     11975\n",
      "weighted avg       0.81      0.81      0.81     11975\n",
      "\n",
      "\n",
      "Classification Report (fold 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.79      0.81      6112\n",
      "         1.0       0.79      0.82      0.81      5862\n",
      "\n",
      "    accuracy                           0.81     11974\n",
      "   macro avg       0.81      0.81      0.81     11974\n",
      "weighted avg       0.81      0.81      0.81     11974\n",
      "\n",
      "\n",
      "Classification Report (fold 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.80      0.81      5937\n",
      "         1.0       0.81      0.83      0.82      6037\n",
      "\n",
      "    accuracy                           0.81     11974\n",
      "   macro avg       0.81      0.81      0.81     11974\n",
      "weighted avg       0.81      0.81      0.81     11974\n",
      "\n",
      "\n",
      "Classification Report (fold 4):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.80      0.81      5932\n",
      "         1.0       0.80      0.82      0.81      6042\n",
      "\n",
      "    accuracy                           0.81     11974\n",
      "   macro avg       0.81      0.81      0.81     11974\n",
      "weighted avg       0.81      0.81      0.81     11974\n",
      "\n",
      "\n",
      "Classification Report (fold 5):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.79      0.80      5902\n",
      "         1.0       0.80      0.82      0.81      6072\n",
      "\n",
      "    accuracy                           0.80     11974\n",
      "   macro avg       0.80      0.80      0.80     11974\n",
      "weighted avg       0.80      0.80      0.80     11974\n",
      "\n",
      "\n",
      "Average Accuracy: 0.8081208212783928\n",
      "Feature importance:\n",
      "of: 12.054042996040351\n",
      "seriously: -8.403971752843871\n",
      "hey: -7.956969713194774\n",
      "amp: 6.631712955578819\n",
      "shoutout: -6.178335199428765\n",
      "wild: -5.7553324011933\n",
      "yo: -5.677776910950305\n",
      "its: 5.291305230083779\n",
      "mess: -5.264597752137817\n",
      "vibe: -5.121791665713461\n"
     ]
    }
   ],
   "source": [
    "LR_clean_tweets(all_df['clean_tweet'], all_df['Human_generated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (fold 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.49      0.49      5978\n",
      "         1.0       0.50      0.50      0.50      5997\n",
      "\n",
      "    accuracy                           0.49     11975\n",
      "   macro avg       0.49      0.49      0.49     11975\n",
      "weighted avg       0.49      0.49      0.49     11975\n",
      "\n",
      "\n",
      "Classification Report (fold 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.50      0.50      5989\n",
      "         1.0       0.49      0.49      0.49      5985\n",
      "\n",
      "    accuracy                           0.49     11974\n",
      "   macro avg       0.49      0.49      0.49     11974\n",
      "weighted avg       0.49      0.49      0.49     11974\n",
      "\n",
      "\n",
      "Classification Report (fold 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.49      0.49      6045\n",
      "         1.0       0.49      0.51      0.50      5929\n",
      "\n",
      "    accuracy                           0.50     11974\n",
      "   macro avg       0.50      0.50      0.50     11974\n",
      "weighted avg       0.50      0.50      0.50     11974\n",
      "\n",
      "\n",
      "Classification Report (fold 4):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.49      0.48      5922\n",
      "         1.0       0.49      0.49      0.49      6052\n",
      "\n",
      "    accuracy                           0.49     11974\n",
      "   macro avg       0.49      0.49      0.49     11974\n",
      "weighted avg       0.49      0.49      0.49     11974\n",
      "\n",
      "\n",
      "Classification Report (fold 5):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.49      0.49      5937\n",
      "         1.0       0.50      0.50      0.50      6037\n",
      "\n",
      "    accuracy                           0.50     11974\n",
      "   macro avg       0.50      0.50      0.50     11974\n",
      "weighted avg       0.50      0.50      0.50     11974\n",
      "\n",
      "\n",
      "Average Accuracy: 0.49409562751305625\n"
     ]
    }
   ],
   "source": [
    "LR_tweet_emoji_profile(all_df, all_df['Human_generated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "6Dcj2dSTFxlO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (fold 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.44      0.02      0.03      5988\n",
      "         1.0       0.50      0.98      0.66      5987\n",
      "\n",
      "    accuracy                           0.50     11975\n",
      "   macro avg       0.47      0.50      0.35     11975\n",
      "weighted avg       0.47      0.50      0.35     11975\n",
      "\n",
      "\n",
      "Classification Report (fold 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.00      0.00      6112\n",
      "         1.0       0.49      1.00      0.66      5862\n",
      "\n",
      "    accuracy                           0.49     11974\n",
      "   macro avg       0.74      0.50      0.33     11974\n",
      "weighted avg       0.75      0.49      0.32     11974\n",
      "\n",
      "\n",
      "Classification Report (fold 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.20      0.28      5937\n",
      "         1.0       0.50      0.80      0.62      6037\n",
      "\n",
      "    accuracy                           0.50     11974\n",
      "   macro avg       0.49      0.50      0.45     11974\n",
      "weighted avg       0.49      0.50      0.45     11974\n",
      "\n",
      "\n",
      "Classification Report (fold 4):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.21      0.30      5932\n",
      "         1.0       0.50      0.78      0.61      6042\n",
      "\n",
      "    accuracy                           0.50     11974\n",
      "   macro avg       0.49      0.50      0.45     11974\n",
      "weighted avg       0.49      0.50      0.46     11974\n",
      "\n",
      "\n",
      "Classification Report (fold 5):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.80      0.61      5902\n",
      "         1.0       0.50      0.19      0.27      6072\n",
      "\n",
      "    accuracy                           0.49     11974\n",
      "   macro avg       0.49      0.50      0.44     11974\n",
      "weighted avg       0.49      0.49      0.44     11974\n",
      "\n",
      "\n",
      "Average Accuracy: 0.49539840008257274\n"
     ]
    }
   ],
   "source": [
    "LR_emoji_profile_count(all_df, all_df['Human_generated'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qm3vPxHBFxvK"
   },
   "source": [
    "## Decision Tree model for combined datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "DG7SJoZ9Fx38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (fold 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.74      0.74      5988\n",
      "         1.0       0.74      0.74      0.74      5987\n",
      "\n",
      "    accuracy                           0.74     11975\n",
      "   macro avg       0.74      0.74      0.74     11975\n",
      "weighted avg       0.74      0.74      0.74     11975\n",
      "\n",
      "\n",
      "Classification Report (fold 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.75      0.75      6112\n",
      "         1.0       0.74      0.74      0.74      5862\n",
      "\n",
      "    accuracy                           0.75     11974\n",
      "   macro avg       0.75      0.75      0.75     11974\n",
      "weighted avg       0.75      0.75      0.75     11974\n",
      "\n",
      "\n",
      "Classification Report (fold 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.76      0.75      5937\n",
      "         1.0       0.76      0.75      0.75      6037\n",
      "\n",
      "    accuracy                           0.75     11974\n",
      "   macro avg       0.75      0.75      0.75     11974\n",
      "weighted avg       0.75      0.75      0.75     11974\n",
      "\n",
      "\n",
      "Classification Report (fold 4):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.75      0.74      5932\n",
      "         1.0       0.75      0.74      0.74      6042\n",
      "\n",
      "    accuracy                           0.74     11974\n",
      "   macro avg       0.74      0.74      0.74     11974\n",
      "weighted avg       0.74      0.74      0.74     11974\n",
      "\n",
      "\n",
      "Classification Report (fold 5):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.74      0.74      5902\n",
      "         1.0       0.75      0.75      0.75      6072\n",
      "\n",
      "    accuracy                           0.74     11974\n",
      "   macro avg       0.74      0.74      0.74     11974\n",
      "weighted avg       0.74      0.74      0.74     11974\n",
      "\n",
      "\n",
      "Average Accuracy: 0.7456030655145996\n",
      "Feature importance:\n",
      "of: 0.1865477000608659\n",
      "throne: 0.14216456915428383\n",
      "let: 0.01651227536985529\n",
      "just: 0.01444229617843121\n",
      "the: 0.0141754606713355\n",
      "be: 0.01219369414298067\n",
      "to: 0.010873495102068491\n",
      "hey: 0.010432813364585417\n",
      "for: 0.010400456978006173\n",
      "out: 0.009762330725215589\n"
     ]
    }
   ],
   "source": [
    "DT_clean_tweets(all_df['clean_tweet'], all_df['Human_generated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_tweet_emoji_profile(all_df['clean_tweet'], all_df['Human_generated'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes too much time to run this function, the result is generally lower than using clean tweets only according to previous observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "15xXUAiCFyGJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (fold 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.20      0.28      5988\n",
      "         1.0       0.50      0.80      0.62      5987\n",
      "\n",
      "    accuracy                           0.50     11975\n",
      "   macro avg       0.50      0.50      0.45     11975\n",
      "weighted avg       0.50      0.50      0.45     11975\n",
      "\n",
      "\n",
      "Classification Report (fold 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.10      0.17      6112\n",
      "         1.0       0.49      0.90      0.63      5862\n",
      "\n",
      "    accuracy                           0.49     11974\n",
      "   macro avg       0.50      0.50      0.40     11974\n",
      "weighted avg       0.50      0.49      0.40     11974\n",
      "\n",
      "\n",
      "Classification Report (fold 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.28      0.36      5937\n",
      "         1.0       0.50      0.72      0.59      6037\n",
      "\n",
      "    accuracy                           0.50     11974\n",
      "   macro avg       0.50      0.50      0.47     11974\n",
      "weighted avg       0.50      0.50      0.48     11974\n",
      "\n",
      "\n",
      "Classification Report (fold 4):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.30      0.37      5932\n",
      "         1.0       0.50      0.69      0.58      6042\n",
      "\n",
      "    accuracy                           0.50     11974\n",
      "   macro avg       0.50      0.50      0.48     11974\n",
      "weighted avg       0.50      0.50      0.48     11974\n",
      "\n",
      "\n",
      "Classification Report (fold 5):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.76      0.60      5902\n",
      "         1.0       0.50      0.22      0.31      6072\n",
      "\n",
      "    accuracy                           0.49     11974\n",
      "   macro avg       0.49      0.49      0.45     11974\n",
      "weighted avg       0.49      0.49      0.45     11974\n",
      "\n",
      "\n",
      "Average Accuracy: 0.4961833841102486\n"
     ]
    }
   ],
   "source": [
    "DT_emoji_profile_count(all_df, all_df['Human_generated'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaulation on new datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The clean tweet column yields the highest accuracy for the logistic regression model among all the models. Therefore, this feature is used for evaluating the model on the new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mental_health = 'mental_health_df_en_10k_del_url_w_stpw.csv'\n",
    "airline = 'airline_df_en_10k_del_url_w_stpw.csv'\n",
    "\n",
    "mental_health_machine = 'mental_health_paraphrase_df.csv'\n",
    "airline_machine = 'airline_paraphrase_df.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>Topics</th>\n",
       "      <th>Human_generated</th>\n",
       "      <th>count_url</th>\n",
       "      <th>count_emoji</th>\n",
       "      <th>count_profile</th>\n",
       "      <th>clean_tweet_Length</th>\n",
       "      <th>Tweet_Length</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>tokenize_clean_tweet</th>\n",
       "      <th>token_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt pls rt and help brave madison get her tomka...</td>\n",
       "      <td>Mental_health</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3298</td>\n",
       "      <td>3945</td>\n",
       "      <td>RT @wordsforwords14 Pls RT and help brave Madi...</td>\n",
       "      <td>['rt', 'pls', 'rt', 'and', 'help', 'brave', 'm...</td>\n",
       "      <td>462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt fyi that leak riverdale script be a draft f...</td>\n",
       "      <td>Mental_health</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>2873</td>\n",
       "      <td>3434</td>\n",
       "      <td>RT @CWRiverdaleNews FYI that leaked Riverdale ...</td>\n",
       "      <td>['rt', 'fyi', 'that', 'leak', 'riverdale', 'sc...</td>\n",
       "      <td>399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt win my prizepackcelebrate 3yrs of http tco ...</td>\n",
       "      <td>Mental_health</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>2741</td>\n",
       "      <td>3098</td>\n",
       "      <td>RT @MeatFreeAthlete WIN my PrizePackCelebratin...</td>\n",
       "      <td>['rt', 'win', 'my', 'prizepackcelebrate', '3yr...</td>\n",
       "      <td>376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rt have u ever want to kiss someone really bad...</td>\n",
       "      <td>Mental_health</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2625</td>\n",
       "      <td>2697</td>\n",
       "      <td>RT @reIatabIe Have u ever wanted to kiss someo...</td>\n",
       "      <td>['rt', 'have', 'u', 'ever', 'want', 'to', 'kis...</td>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt right wing independent greek party agree to...</td>\n",
       "      <td>Mental_health</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2441</td>\n",
       "      <td>2516</td>\n",
       "      <td>RT @BBCBreaking Right-wing Independent Greeks ...</td>\n",
       "      <td>['rt', 'right', 'wing', 'independent', 'greek'...</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19920</th>\n",
       "      <td>sofa shopping yay</td>\n",
       "      <td>Mental_Health</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>Sofa shopping Yay</td>\n",
       "      <td>['sofa', 'shopping', 'yay']</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19921</th>\n",
       "      <td>round 2 tonight</td>\n",
       "      <td>Mental_Health</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>29</td>\n",
       "      <td>@bayleeideker round 2 tonight</td>\n",
       "      <td>['round', '2', 'tonight']</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19922</th>\n",
       "      <td>so freak stoke</td>\n",
       "      <td>Mental_Health</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>@5SOS so freaking stoked</td>\n",
       "      <td>['so', 'freak', 'stoke']</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19923</th>\n",
       "      <td>chill at home</td>\n",
       "      <td>Mental_Health</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>@lexiloungin chilling at home</td>\n",
       "      <td>['chill', 'at', 'home']</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19924</th>\n",
       "      <td>seriously stop lie</td>\n",
       "      <td>Mental_Health</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>35</td>\n",
       "      <td>@mahctekydnam seriously stop lying</td>\n",
       "      <td>['seriously', 'stop', 'lie']</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19925 rows √ó 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             clean_tweet         Topics  \\\n",
       "0      rt pls rt and help brave madison get her tomka...  Mental_health   \n",
       "1      rt fyi that leak riverdale script be a draft f...  Mental_health   \n",
       "2      rt win my prizepackcelebrate 3yrs of http tco ...  Mental_health   \n",
       "3      rt have u ever want to kiss someone really bad...  Mental_health   \n",
       "4      rt right wing independent greek party agree to...  Mental_health   \n",
       "...                                                  ...            ...   \n",
       "19920                                  sofa shopping yay  Mental_Health   \n",
       "19921                                    round 2 tonight  Mental_Health   \n",
       "19922                                     so freak stoke  Mental_Health   \n",
       "19923                                      chill at home  Mental_Health   \n",
       "19924                                 seriously stop lie  Mental_Health   \n",
       "\n",
       "       Human_generated  count_url  count_emoji  count_profile  \\\n",
       "0                    1          0            0             46   \n",
       "1                    1          5            0             23   \n",
       "2                    1          2            0             27   \n",
       "3                    1          0            0              7   \n",
       "4                    1          0            0              4   \n",
       "...                ...        ...          ...            ...   \n",
       "19920                0          0            0              0   \n",
       "19921                0          0            0              1   \n",
       "19922                0          0            0              1   \n",
       "19923                0          0            0              1   \n",
       "19924                0          0            0              1   \n",
       "\n",
       "       clean_tweet_Length  Tweet_Length  \\\n",
       "0                    3298          3945   \n",
       "1                    2873          3434   \n",
       "2                    2741          3098   \n",
       "3                    2625          2697   \n",
       "4                    2441          2516   \n",
       "...                   ...           ...   \n",
       "19920                  17            18   \n",
       "19921                  15            29   \n",
       "19922                  18            24   \n",
       "19923                  16            29   \n",
       "19924                  20            35   \n",
       "\n",
       "                                                   Tweet  \\\n",
       "0      RT @wordsforwords14 Pls RT and help brave Madi...   \n",
       "1      RT @CWRiverdaleNews FYI that leaked Riverdale ...   \n",
       "2      RT @MeatFreeAthlete WIN my PrizePackCelebratin...   \n",
       "3      RT @reIatabIe Have u ever wanted to kiss someo...   \n",
       "4      RT @BBCBreaking Right-wing Independent Greeks ...   \n",
       "...                                                  ...   \n",
       "19920                                 Sofa shopping Yay    \n",
       "19921                      @bayleeideker round 2 tonight   \n",
       "19922                           @5SOS so freaking stoked   \n",
       "19923                      @lexiloungin chilling at home   \n",
       "19924                @mahctekydnam seriously stop lying    \n",
       "\n",
       "                                    tokenize_clean_tweet  token_length  \n",
       "0      ['rt', 'pls', 'rt', 'and', 'help', 'brave', 'm...           462  \n",
       "1      ['rt', 'fyi', 'that', 'leak', 'riverdale', 'sc...           399  \n",
       "2      ['rt', 'win', 'my', 'prizepackcelebrate', '3yr...           376  \n",
       "3      ['rt', 'have', 'u', 'ever', 'want', 'to', 'kis...           369  \n",
       "4      ['rt', 'right', 'wing', 'independent', 'greek'...           287  \n",
       "...                                                  ...           ...  \n",
       "19920                        ['sofa', 'shopping', 'yay']             3  \n",
       "19921                          ['round', '2', 'tonight']             3  \n",
       "19922                           ['so', 'freak', 'stoke']             3  \n",
       "19923                            ['chill', 'at', 'home']             3  \n",
       "19924                       ['seriously', 'stop', 'lie']             3  \n",
       "\n",
       "[19925 rows x 11 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mental_health_df = pd.read_csv(mental_health)\n",
    "mental_health_machine_df = pd.read_csv(mental_health_machine)\n",
    "mental_health_machine_df = mental_health_machine_df.iloc[:, :11]\n",
    "mental_health_df = pd.concat([mental_health_df.iloc[:rows_per_datasets], mental_health_machine_df.iloc[:rows_per_datasets]], axis=0, ignore_index=True)\n",
    "mental_health_df = mental_health_df.dropna()\n",
    "mental_health_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>Topics</th>\n",
       "      <th>Human_generated</th>\n",
       "      <th>count_url</th>\n",
       "      <th>count_emoji</th>\n",
       "      <th>count_profile</th>\n",
       "      <th>clean_tweet_Length</th>\n",
       "      <th>Tweet_Length</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>tokenize_clean_tweet</th>\n",
       "      <th>token_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ahah that be why i love sw 2015 02 20 171842 0...</td>\n",
       "      <td>Airline</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1546</td>\n",
       "      <td>1701</td>\n",
       "      <td>@SouthwestAir Ahah That is why\\nI love SW^^201...</td>\n",
       "      <td>['ahah', 'that', 'be', 'why', 'i', 'love', 'sw...</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>can i put sun in my carry on rt united right n...</td>\n",
       "      <td>Airline</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1005</td>\n",
       "      <td>1050</td>\n",
       "      <td>Can I put sun in my carry on RT united @ant_kn...</td>\n",
       "      <td>['can', 'i', 'put', 'sun', 'in', 'my', 'carry'...</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>noooo don t do it please don t do it rt our fl...</td>\n",
       "      <td>Airline</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>735</td>\n",
       "      <td>751</td>\n",
       "      <td>Noooo don't do it please don't do it RT @JetBl...</td>\n",
       "      <td>['noooo', 'don', 't', 'do', 'it', 'please', 'd...</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>by the grace of god i make it usairway we don ...</td>\n",
       "      <td>Airline</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>605</td>\n",
       "      <td>633</td>\n",
       "      <td>BY THE GRACE OF GOD I MADE IT USAirways @__RWG...</td>\n",
       "      <td>['by', 'the', 'grace', 'of', 'god', 'i', 'make...</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stop the madness our fleet s on fleek http tco...</td>\n",
       "      <td>Airline</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>612</td>\n",
       "      <td>636</td>\n",
       "      <td>Stop the madness @JetBlue Our fleet's on fleek...</td>\n",
       "      <td>['stop', 'the', 'madness', 'our', 'fleet', 's'...</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19958</th>\n",
       "      <td>do and do thank for the help</td>\n",
       "      <td>Airline</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>41</td>\n",
       "      <td>@united Done and done thanks for the help</td>\n",
       "      <td>['do', 'and', 'do', 'thank', 'for', 'the', 'he...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19959</th>\n",
       "      <td>line up lax avgeek http tco djhxvjt201</td>\n",
       "      <td>Airline</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>74</td>\n",
       "      <td>@SouthwestAir line up @LAX #LAX @AirlineGeeks ...</td>\n",
       "      <td>['line', 'up', 'lax', 'avgeek', 'http', 'tco',...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19960</th>\n",
       "      <td>i ain t ever fly again getmeouttahere</td>\n",
       "      <td>Airline</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>58</td>\n",
       "      <td>@JetBlue I ain't ever flying @United again #ge...</td>\n",
       "      <td>['i', 'ain', 't', 'ever', 'fly', 'again', 'get...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19961</th>\n",
       "      <td>great chat with you appreciate the help</td>\n",
       "      <td>Airline</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>62</td>\n",
       "      <td>@united @annricord great chatting with you app...</td>\n",
       "      <td>['great', 'chat', 'with', 'you', 'appreciate',...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19962</th>\n",
       "      <td>5 hour maintenance delay drive i crazy</td>\n",
       "      <td>Airline</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>52</td>\n",
       "      <td>@AlaskaAir 5 hour maintenance delay driving me...</td>\n",
       "      <td>['5', 'hour', 'maintenance', 'delay', 'drive',...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19963 rows √ó 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             clean_tweet   Topics  \\\n",
       "0      ahah that be why i love sw 2015 02 20 171842 0...  Airline   \n",
       "1      can i put sun in my carry on rt united right n...  Airline   \n",
       "2      noooo don t do it please don t do it rt our fl...  Airline   \n",
       "3      by the grace of god i make it usairway we don ...  Airline   \n",
       "4      stop the madness our fleet s on fleek http tco...  Airline   \n",
       "...                                                  ...      ...   \n",
       "19958                       do and do thank for the help  Airline   \n",
       "19959             line up lax avgeek http tco djhxvjt201  Airline   \n",
       "19960              i ain t ever fly again getmeouttahere  Airline   \n",
       "19961            great chat with you appreciate the help  Airline   \n",
       "19962             5 hour maintenance delay drive i crazy  Airline   \n",
       "\n",
       "       Human_generated  count_url  count_emoji  count_profile  \\\n",
       "0                    1          0            0             12   \n",
       "1                    1          0            0              6   \n",
       "2                    1          0            0              2   \n",
       "3                    1          0            0              3   \n",
       "4                    1          0            0              3   \n",
       "...                ...        ...          ...            ...   \n",
       "19958                0          0            0              1   \n",
       "19959                0          0            0              3   \n",
       "19960                0          0            0              2   \n",
       "19961                0          0            0              2   \n",
       "19962                0          0            0              1   \n",
       "\n",
       "       clean_tweet_Length  Tweet_Length  \\\n",
       "0                    1546          1701   \n",
       "1                    1005          1050   \n",
       "2                     735           751   \n",
       "3                     605           633   \n",
       "4                     612           636   \n",
       "...                   ...           ...   \n",
       "19958                  33            41   \n",
       "19959                  43            74   \n",
       "19960                  42            58   \n",
       "19961                  43            62   \n",
       "19962                  41            52   \n",
       "\n",
       "                                                   Tweet  \\\n",
       "0      @SouthwestAir Ahah That is why\\nI love SW^^201...   \n",
       "1      Can I put sun in my carry on RT united @ant_kn...   \n",
       "2      Noooo don't do it please don't do it RT @JetBl...   \n",
       "3      BY THE GRACE OF GOD I MADE IT USAirways @__RWG...   \n",
       "4      Stop the madness @JetBlue Our fleet's on fleek...   \n",
       "...                                                  ...   \n",
       "19958          @united Done and done thanks for the help   \n",
       "19959  @SouthwestAir line up @LAX #LAX @AirlineGeeks ...   \n",
       "19960  @JetBlue I ain't ever flying @United again #ge...   \n",
       "19961  @united @annricord great chatting with you app...   \n",
       "19962  @AlaskaAir 5 hour maintenance delay driving me...   \n",
       "\n",
       "                                    tokenize_clean_tweet token_length  \n",
       "0      ['ahah', 'that', 'be', 'why', 'i', 'love', 'sw...          208  \n",
       "1      ['can', 'i', 'put', 'sun', 'in', 'my', 'carry'...          134  \n",
       "2      ['noooo', 'don', 't', 'do', 'it', 'please', 'd...           98  \n",
       "3      ['by', 'the', 'grace', 'of', 'god', 'i', 'make...           98  \n",
       "4      ['stop', 'the', 'madness', 'our', 'fleet', 's'...           68  \n",
       "...                                                  ...          ...  \n",
       "19958  ['do', 'and', 'do', 'thank', 'for', 'the', 'he...            7  \n",
       "19959  ['line', 'up', 'lax', 'avgeek', 'http', 'tco',...            7  \n",
       "19960  ['i', 'ain', 't', 'ever', 'fly', 'again', 'get...            7  \n",
       "19961  ['great', 'chat', 'with', 'you', 'appreciate',...            7  \n",
       "19962  ['5', 'hour', 'maintenance', 'delay', 'drive',...            7  \n",
       "\n",
       "[19963 rows x 11 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airline_df = pd.read_csv(airline)\n",
    "airline_machine_df = pd.read_csv(airline_machine)\n",
    "airline_machine_df = airline_machine_df.iloc[:, :11]\n",
    "airline_df = pd.concat([airline_df.iloc[:rows_per_datasets], airline_machine_df.iloc[:rows_per_datasets]], axis=0, ignore_index=True)\n",
    "airline_df = airline_df.dropna()\n",
    "airline_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to train Logistic Regression model\n",
    "def train_lr_model(X_train, y_train):\n",
    "    lr_model = LogisticRegression(max_iter = 1000, random_state = 5)\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    return lr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate LR model on new data\n",
    "def evaluate_lr_model(lr_model, X_test, y_test, accuracies):\n",
    "    y_pred = lr_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    accuracies.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to train LR model using KFold cross-validation\n",
    "def train_lr_with_kfold(features, target, vectorizer, num_folds = 5):\n",
    "    X = features\n",
    "    y = target\n",
    "\n",
    "    kf = KFold(n_splits = num_folds, shuffle = True, random_state = 5)\n",
    "\n",
    "    accuracies = []\n",
    "    trained_models = []\n",
    "\n",
    "    # Create a pool of worker processes\n",
    "    num_cores = 32\n",
    "    pool = Pool(processes=num_cores)\n",
    "\n",
    "    for fold_idx, (train_index, test_index) in enumerate(kf.split(X), 1):\n",
    "        X_train_tfidf = vectorizer.transform(X.iloc[train_index])\n",
    "        X_test_tfidf = vectorizer.transform(X.iloc[test_index])\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # Perform parallel training and prediction\n",
    "        results = pool.starmap(train_lr_model, [(X_train_tfidf, y_train)])\n",
    "\n",
    "        for lr_model in results:\n",
    "            trained_models.append(lr_model)\n",
    "\n",
    "            # Evaluate the trained model\n",
    "            accuracy = lr_model.score(X_test_tfidf, y_test)\n",
    "            accuracies.append(accuracy)\n",
    "\n",
    "\n",
    "    # Close the pool of worker processes\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    return trained_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mental health dataset evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation of Model 1 on mental_health_df:\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.71      0.67      9925\n",
      "           1       0.67      0.58      0.62     10000\n",
      "\n",
      "    accuracy                           0.65     19925\n",
      "   macro avg       0.65      0.65      0.64     19925\n",
      "weighted avg       0.65      0.65      0.64     19925\n",
      "\n",
      "\n",
      "Evaluation of Model 2 on mental_health_df:\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.71      0.67      9925\n",
      "           1       0.67      0.59      0.63     10000\n",
      "\n",
      "    accuracy                           0.65     19925\n",
      "   macro avg       0.65      0.65      0.65     19925\n",
      "weighted avg       0.65      0.65      0.65     19925\n",
      "\n",
      "\n",
      "Evaluation of Model 3 on mental_health_df:\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.72      0.67      9925\n",
      "           1       0.67      0.58      0.62     10000\n",
      "\n",
      "    accuracy                           0.65     19925\n",
      "   macro avg       0.65      0.65      0.65     19925\n",
      "weighted avg       0.65      0.65      0.65     19925\n",
      "\n",
      "\n",
      "Evaluation of Model 4 on mental_health_df:\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.71      0.67      9925\n",
      "           1       0.67      0.59      0.63     10000\n",
      "\n",
      "    accuracy                           0.65     19925\n",
      "   macro avg       0.65      0.65      0.65     19925\n",
      "weighted avg       0.65      0.65      0.65     19925\n",
      "\n",
      "\n",
      "Evaluation of Model 5 on mental_health_df:\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.71      0.66      9925\n",
      "           1       0.67      0.59      0.62     10000\n",
      "\n",
      "    accuracy                           0.65     19925\n",
      "   macro avg       0.65      0.65      0.64     19925\n",
      "weighted avg       0.65      0.65      0.64     19925\n",
      "\n",
      "\n",
      "Average Accuracy: 0.6470664993726475\n"
     ]
    }
   ],
   "source": [
    "# Extract features and target from datasets\n",
    "all_df_features = all_df['clean_tweet']\n",
    "all_df_target = all_df['Human_generated']\n",
    "\n",
    "mental_health_df_features = mental_health_df['clean_tweet']\n",
    "mental_health_df_target = mental_health_df['Human_generated']\n",
    "\n",
    "# Combine text from both datasets\n",
    "combined_text = pd.concat([all_df_features, mental_health_df_features], axis=0)\n",
    "\n",
    "# Initialize TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "vectorizer.fit(combined_text.apply(preprocess_text))\n",
    "\n",
    "trained_models = train_lr_with_kfold(all_df_features, all_df_target, vectorizer)\n",
    "\n",
    "accuracies = []\n",
    "# Evaluate the trained models on mental_health_df\n",
    "for idx, lr_model in enumerate(trained_models, 1):\n",
    "    print(f\"\\nEvaluation of Model {idx} on mental_health_df:\")\n",
    "    X_mental_health_df = vectorizer.transform(mental_health_df_features.apply(preprocess_text))\n",
    "    evaluate_lr_model(lr_model, X_mental_health_df, mental_health_df_target, accuracies)\n",
    "    \n",
    "average_accuracy = sum(accuracies) / len(accuracies)\n",
    "print(\"\\nAverage Accuracy:\", average_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Airline dataset evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation of Model 1 on airline_df:\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.67      0.68      9963\n",
      "           1       0.68      0.70      0.69     10000\n",
      "\n",
      "    accuracy                           0.69     19963\n",
      "   macro avg       0.69      0.69      0.69     19963\n",
      "weighted avg       0.69      0.69      0.69     19963\n",
      "\n",
      "\n",
      "Evaluation of Model 2 on airline_df:\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.67      0.68      9963\n",
      "           1       0.68      0.71      0.69     10000\n",
      "\n",
      "    accuracy                           0.69     19963\n",
      "   macro avg       0.69      0.69      0.69     19963\n",
      "weighted avg       0.69      0.69      0.69     19963\n",
      "\n",
      "\n",
      "Evaluation of Model 3 on airline_df:\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.67      0.68      9963\n",
      "           1       0.68      0.71      0.69     10000\n",
      "\n",
      "    accuracy                           0.69     19963\n",
      "   macro avg       0.69      0.69      0.69     19963\n",
      "weighted avg       0.69      0.69      0.69     19963\n",
      "\n",
      "\n",
      "Evaluation of Model 4 on airline_df:\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.67      0.68      9963\n",
      "           1       0.68      0.70      0.69     10000\n",
      "\n",
      "    accuracy                           0.69     19963\n",
      "   macro avg       0.69      0.69      0.69     19963\n",
      "weighted avg       0.69      0.69      0.69     19963\n",
      "\n",
      "\n",
      "Evaluation of Model 5 on airline_df:\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.66      0.68      9963\n",
      "           1       0.68      0.71      0.69     10000\n",
      "\n",
      "    accuracy                           0.69     19963\n",
      "   macro avg       0.69      0.69      0.69     19963\n",
      "weighted avg       0.69      0.69      0.69     19963\n",
      "\n",
      "\n",
      "Average Accuracy: 0.6866803586635275\n"
     ]
    }
   ],
   "source": [
    "# Extract features and target from datasets\n",
    "airline_df_features = airline_df['clean_tweet']\n",
    "airline_df_target = airline_df['Human_generated']\n",
    "\n",
    "# Combine text from both datasets\n",
    "combined_text = pd.concat([all_df_features, airline_df_features], axis=0)\n",
    "\n",
    "# Initialize TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "vectorizer.fit(combined_text.apply(preprocess_text))\n",
    "\n",
    "trained_models = train_lr_with_kfold(all_df_features, all_df_target, vectorizer)\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "# Evaluate the trained models on airline_df\n",
    "for idx, lr_model in enumerate(trained_models, 1):\n",
    "    print(f\"\\nEvaluation of Model {idx} on airline_df:\")\n",
    "    X_airline_df = vectorizer.transform(airline_df_features.apply(preprocess_text))\n",
    "    evaluate_lr_model(lr_model, X_airline_df, airline_df_target, accuracies)\n",
    "\n",
    "average_accuracy = sum(accuracies) / len(accuracies)\n",
    "print(\"\\nAverage Accuracy:\", average_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
